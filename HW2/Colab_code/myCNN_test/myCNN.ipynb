{"cells":[{"cell_type":"markdown","metadata":{"id":"py85-Cna3C-m"},"source":["## HW2\n","\n","> using ResNet"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BN8Z-T4FV6xV","executionInfo":{"status":"ok","timestamp":1649381959782,"user_tz":-480,"elapsed":26055,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}},"outputId":"aa34d570-1e8e-4e8f-8db7-4fece9776469"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7BIE8HEAA0m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8e0ba58-e422-4920-8315-49b611d65464","executionInfo":{"status":"ok","timestamp":1649381965739,"user_tz":-480,"elapsed":5962,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["3b39941535da4cad84a887f4b601a69d","ca1acfdc5b074343b45c74607b702ca9","5012cbbf00bf4181865d46a036ea2649","84ae21a4647848828e9b2632dd8eb68d","92c0f46f16974f65adbb760ed801b3eb","6f990c5e36ab4959abde7e142733f917","6a194e9b647b45ba98202149cdb78e98","a30597c150ea4fb9882145efc7748fcc","b27adeab377948f6adff391c9db0ce1f","4886150fdccd488989ed93668cffc94f","4c8174503ac64df190ab6a45cdeaf0bd"]},"id":"DE237Uh3ABKY","outputId":"6d90e608-ffb7-4e7c-e4fd-130a9c79910f","executionInfo":{"status":"ok","timestamp":1649381975867,"user_tz":-480,"elapsed":10138,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b39941535da4cad84a887f4b601a69d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# see more data augmentation https://pytorch.org/vision/stable/transforms.html\n","mean = (0.5071, 0.4867, 0.4408)\n","std = (0.2675, 0.2565, 0.2761)\n","train_transform = transforms.Compose(\n","    [transforms.RandomHorizontalFlip(p=0.5),\n","     transforms.ToTensor(),\n","     transforms.Normalize(mean, std)]) # calculte yourself\n","\n","test_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize(mean, std)]) # calculte yourself\n","\n","batch_size = 64\n","num_classes = 100    # check\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PDC78MUALYM"},"outputs":[],"source":["class my_CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # self.pre = nn.Sequential(\n","        #     nn.Conv2d(3, batch_size, 3, padding=1),\n","        #     nn.BatchNorm2d(64),\n","        #     nn.ReLU(inplace=True)\n","        # )\n","\n","        self.conv_block = nn.Sequential(\n","            # unit 1\n","            nn.Conv2d(3,batch_size,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.Conv2d(3,batch_size,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,stride=2,padding=(1,1)),\n","\n","            #unit 2\n","            nn.Conv2d(batch_size,batch_size*2,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.Conv2d(batch_size,batch_size*2,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,stride=2,padding=(1,1)),\n","\n","            #unit 3\n","            nn.Conv2d(batch_size*2,batch_size*4,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.Conv2d(batch_size*2,batch_size*4,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,stride=2,padding=(1,1)),\n","\n","            #unit 4\n","            nn.Conv2d(batch_size*4,batch_size*8,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.Conv2d(batch_size*4,batch_size*8,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,stride=2,padding=(1,1)),\n","\n","            #unit 2\n","            nn.Conv2d(batch_size*8,batch_size*8,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.Conv2d(batch_size*8,batch_size*8,kernel_size=(3,3),padding=(1,1)),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,stride=2,padding=(1,1))\n","        )\n","\n","        self.dense_block = nn.Sequential(\n","            nn.Linear(batch_size*8, batch_size*4),\n","            nn.ReLU(),\n","            nn.Linear(batch_size*4, batch_size*2),\n","            nn.ReLU(),\n","            nn.Linear(batch_size*2, 100)\n","        )\n","\n","    def forward(self, x) :\n","        # x = self.pre(x)\n","        conv_out = self.conv_block(x)\n","        res = conv_out.view(conv_out.size(0), -1) # view(-1) same as flatten\n","        out = self.dense_block(res)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a98cb3dfb82a4fb09a9f36192cb06212","551c66fb05ba4fb693c2cac593602e28","7cd0dad13b7e431487e8a4b64915ef04","57ac473189d643bbb81dbdbd1d54bba2","4b950d0d349a4fc9963f8108635278dd","d7cac480bc8142f4a3bb83c3e1738676","637f471e34824649a586cb1bc10bea98","3a78dd8993a048868de62049d5502356","26ae1508aa424209907dbc58a166e536","4e1d6ccf4d374a238c1e3e86f3b391a2","21d16ec2a077461d934f8e0f416bb167"]},"id":"GzOoI9FCAiz3","outputId":"db4f2675-e2d3-4adf-dbd2-236f49b90037","executionInfo":{"status":"ok","timestamp":1649381986395,"user_tz":-480,"elapsed":10534,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a98cb3dfb82a4fb09a9f36192cb06212"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): Identity()\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",")"]},"metadata":{},"execution_count":5}],"source":["# pick one\n","\n","# 1. model defined by yourself\n","# model = my_CNN()        \n","   \n","# 2. off-the-shelf model\n","# see https://pytorch.org/vision/stable/models.html\n","# nn.Linear https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n","model = models.resnet50(pretrained=True) \n","model.fc = torch.nn.Linear(2048, num_classes)\n","model.conv1 = nn.Conv2d(3,64,kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n","model.maxpool = nn.Identity()\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxZ41jR1BT28"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=1e-4)"]},{"cell_type":"code","source":["total_epoch = 200\n","print_per_iteration = 100\n","save_path = '/content/drive/MyDrive/Colab Notebooks/ML_HW2/myCNN_test/modify_ResNet.pth'\n","\n","for epoch in range(total_epoch):  # loop over the dataset multiple times\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # print(inputs)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        if (i+1) % print_per_iteration == 0:    # print every 2000 mini-batches\n","            print(f'[ep {epoch + 1}][{i + 1:5d}/{len(trainloader):5d}] loss: {loss.item():.3f}')\n","    torch.save(model, save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LTzbiubhyf2","outputId":"aa238df0-14b5-4f0b-c285-f31328197040","executionInfo":{"status":"ok","timestamp":1649402912465,"user_tz":-480,"elapsed":18715743,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ep 1][  100/  782] loss: 4.602\n","[ep 1][  200/  782] loss: 4.621\n","[ep 1][  300/  782] loss: 4.510\n","[ep 1][  400/  782] loss: 4.556\n","[ep 1][  500/  782] loss: 4.486\n","[ep 1][  600/  782] loss: 4.458\n","[ep 1][  700/  782] loss: 4.355\n","[ep 2][  100/  782] loss: 4.163\n","[ep 2][  200/  782] loss: 4.177\n","[ep 2][  300/  782] loss: 4.063\n","[ep 2][  400/  782] loss: 4.030\n","[ep 2][  500/  782] loss: 4.074\n","[ep 2][  600/  782] loss: 3.864\n","[ep 2][  700/  782] loss: 3.842\n","[ep 3][  100/  782] loss: 3.793\n","[ep 3][  200/  782] loss: 3.844\n","[ep 3][  300/  782] loss: 3.763\n","[ep 3][  400/  782] loss: 3.533\n","[ep 3][  500/  782] loss: 3.697\n","[ep 3][  600/  782] loss: 3.790\n","[ep 3][  700/  782] loss: 3.438\n","[ep 4][  100/  782] loss: 3.297\n","[ep 4][  200/  782] loss: 3.284\n","[ep 4][  300/  782] loss: 3.244\n","[ep 4][  400/  782] loss: 3.250\n","[ep 4][  500/  782] loss: 3.212\n","[ep 4][  600/  782] loss: 3.034\n","[ep 4][  700/  782] loss: 3.145\n","[ep 5][  100/  782] loss: 2.997\n","[ep 5][  200/  782] loss: 2.768\n","[ep 5][  300/  782] loss: 2.703\n","[ep 5][  400/  782] loss: 2.840\n","[ep 5][  500/  782] loss: 2.432\n","[ep 5][  600/  782] loss: 2.725\n","[ep 5][  700/  782] loss: 2.353\n","[ep 6][  100/  782] loss: 2.649\n","[ep 6][  200/  782] loss: 2.672\n","[ep 6][  300/  782] loss: 2.733\n","[ep 6][  400/  782] loss: 2.426\n","[ep 6][  500/  782] loss: 2.492\n","[ep 6][  600/  782] loss: 2.165\n","[ep 6][  700/  782] loss: 1.906\n","[ep 7][  100/  782] loss: 2.242\n","[ep 7][  200/  782] loss: 2.177\n","[ep 7][  300/  782] loss: 1.977\n","[ep 7][  400/  782] loss: 2.153\n","[ep 7][  500/  782] loss: 1.775\n","[ep 7][  600/  782] loss: 1.875\n","[ep 7][  700/  782] loss: 2.220\n","[ep 8][  100/  782] loss: 1.938\n","[ep 8][  200/  782] loss: 2.129\n","[ep 8][  300/  782] loss: 1.937\n","[ep 8][  400/  782] loss: 2.036\n","[ep 8][  500/  782] loss: 1.834\n","[ep 8][  600/  782] loss: 1.965\n","[ep 8][  700/  782] loss: 2.053\n","[ep 9][  100/  782] loss: 1.831\n","[ep 9][  200/  782] loss: 1.503\n","[ep 9][  300/  782] loss: 2.134\n","[ep 9][  400/  782] loss: 1.732\n","[ep 9][  500/  782] loss: 1.801\n","[ep 9][  600/  782] loss: 1.652\n","[ep 9][  700/  782] loss: 1.554\n","[ep 10][  100/  782] loss: 1.708\n","[ep 10][  200/  782] loss: 1.732\n","[ep 10][  300/  782] loss: 1.464\n","[ep 10][  400/  782] loss: 1.525\n","[ep 10][  500/  782] loss: 1.908\n","[ep 10][  600/  782] loss: 1.639\n","[ep 10][  700/  782] loss: 1.364\n","[ep 11][  100/  782] loss: 1.561\n","[ep 11][  200/  782] loss: 1.365\n","[ep 11][  300/  782] loss: 1.259\n","[ep 11][  400/  782] loss: 1.411\n","[ep 11][  500/  782] loss: 1.245\n","[ep 11][  600/  782] loss: 1.414\n","[ep 11][  700/  782] loss: 1.625\n","[ep 12][  100/  782] loss: 1.272\n","[ep 12][  200/  782] loss: 1.344\n","[ep 12][  300/  782] loss: 1.561\n","[ep 12][  400/  782] loss: 1.016\n","[ep 12][  500/  782] loss: 0.976\n","[ep 12][  600/  782] loss: 1.033\n","[ep 12][  700/  782] loss: 1.356\n","[ep 13][  100/  782] loss: 1.416\n","[ep 13][  200/  782] loss: 1.317\n","[ep 13][  300/  782] loss: 1.124\n","[ep 13][  400/  782] loss: 1.075\n","[ep 13][  500/  782] loss: 1.053\n","[ep 13][  600/  782] loss: 1.498\n","[ep 13][  700/  782] loss: 1.329\n","[ep 14][  100/  782] loss: 1.116\n","[ep 14][  200/  782] loss: 1.236\n","[ep 14][  300/  782] loss: 1.068\n","[ep 14][  400/  782] loss: 1.096\n","[ep 14][  500/  782] loss: 1.557\n","[ep 14][  600/  782] loss: 1.236\n","[ep 14][  700/  782] loss: 1.267\n","[ep 15][  100/  782] loss: 1.144\n","[ep 15][  200/  782] loss: 1.381\n","[ep 15][  300/  782] loss: 1.069\n","[ep 15][  400/  782] loss: 1.225\n","[ep 15][  500/  782] loss: 0.895\n","[ep 15][  600/  782] loss: 1.110\n","[ep 15][  700/  782] loss: 1.066\n","[ep 16][  100/  782] loss: 1.054\n","[ep 16][  200/  782] loss: 1.238\n","[ep 16][  300/  782] loss: 1.093\n","[ep 16][  400/  782] loss: 1.075\n","[ep 16][  500/  782] loss: 1.120\n","[ep 16][  600/  782] loss: 1.014\n","[ep 16][  700/  782] loss: 0.921\n","[ep 17][  100/  782] loss: 0.743\n","[ep 17][  200/  782] loss: 1.250\n","[ep 17][  300/  782] loss: 0.934\n","[ep 17][  400/  782] loss: 1.006\n","[ep 17][  500/  782] loss: 0.795\n","[ep 17][  600/  782] loss: 0.999\n","[ep 17][  700/  782] loss: 0.952\n","[ep 18][  100/  782] loss: 0.935\n","[ep 18][  200/  782] loss: 0.895\n","[ep 18][  300/  782] loss: 0.904\n","[ep 18][  400/  782] loss: 0.971\n","[ep 18][  500/  782] loss: 1.190\n","[ep 18][  600/  782] loss: 0.650\n","[ep 18][  700/  782] loss: 0.722\n","[ep 19][  100/  782] loss: 0.972\n","[ep 19][  200/  782] loss: 0.926\n","[ep 19][  300/  782] loss: 1.036\n","[ep 19][  400/  782] loss: 0.856\n","[ep 19][  500/  782] loss: 1.265\n","[ep 19][  600/  782] loss: 0.825\n","[ep 19][  700/  782] loss: 0.804\n","[ep 20][  100/  782] loss: 0.897\n","[ep 20][  200/  782] loss: 0.911\n","[ep 20][  300/  782] loss: 0.932\n","[ep 20][  400/  782] loss: 0.857\n","[ep 20][  500/  782] loss: 0.944\n","[ep 20][  600/  782] loss: 0.931\n","[ep 20][  700/  782] loss: 0.798\n","[ep 21][  100/  782] loss: 0.922\n","[ep 21][  200/  782] loss: 0.705\n","[ep 21][  300/  782] loss: 0.507\n","[ep 21][  400/  782] loss: 1.023\n","[ep 21][  500/  782] loss: 0.802\n","[ep 21][  600/  782] loss: 0.793\n","[ep 21][  700/  782] loss: 0.699\n","[ep 22][  100/  782] loss: 0.702\n","[ep 22][  200/  782] loss: 0.802\n","[ep 22][  300/  782] loss: 0.786\n","[ep 22][  400/  782] loss: 0.618\n","[ep 22][  500/  782] loss: 0.647\n","[ep 22][  600/  782] loss: 0.736\n","[ep 22][  700/  782] loss: 0.871\n","[ep 23][  100/  782] loss: 0.614\n","[ep 23][  200/  782] loss: 0.553\n","[ep 23][  300/  782] loss: 0.784\n","[ep 23][  400/  782] loss: 0.815\n","[ep 23][  500/  782] loss: 0.861\n","[ep 23][  600/  782] loss: 0.827\n","[ep 23][  700/  782] loss: 0.814\n","[ep 24][  100/  782] loss: 0.989\n","[ep 24][  200/  782] loss: 0.579\n","[ep 24][  300/  782] loss: 0.701\n","[ep 24][  400/  782] loss: 0.632\n","[ep 24][  500/  782] loss: 0.779\n","[ep 24][  600/  782] loss: 0.748\n","[ep 24][  700/  782] loss: 0.631\n","[ep 25][  100/  782] loss: 0.487\n","[ep 25][  200/  782] loss: 0.648\n","[ep 25][  300/  782] loss: 0.722\n","[ep 25][  400/  782] loss: 0.499\n","[ep 25][  500/  782] loss: 0.662\n","[ep 25][  600/  782] loss: 0.492\n","[ep 25][  700/  782] loss: 0.833\n","[ep 26][  100/  782] loss: 0.567\n","[ep 26][  200/  782] loss: 0.671\n","[ep 26][  300/  782] loss: 0.656\n","[ep 26][  400/  782] loss: 0.653\n","[ep 26][  500/  782] loss: 0.539\n","[ep 26][  600/  782] loss: 0.516\n","[ep 26][  700/  782] loss: 0.420\n","[ep 27][  100/  782] loss: 0.492\n","[ep 27][  200/  782] loss: 0.545\n","[ep 27][  300/  782] loss: 0.628\n","[ep 27][  400/  782] loss: 0.780\n","[ep 27][  500/  782] loss: 0.455\n","[ep 27][  600/  782] loss: 0.537\n","[ep 27][  700/  782] loss: 0.620\n","[ep 28][  100/  782] loss: 0.651\n","[ep 28][  200/  782] loss: 0.525\n","[ep 28][  300/  782] loss: 0.591\n","[ep 28][  400/  782] loss: 0.663\n","[ep 28][  500/  782] loss: 0.575\n","[ep 28][  600/  782] loss: 0.588\n","[ep 28][  700/  782] loss: 0.591\n","[ep 29][  100/  782] loss: 0.516\n","[ep 29][  200/  782] loss: 0.497\n","[ep 29][  300/  782] loss: 0.440\n","[ep 29][  400/  782] loss: 0.667\n","[ep 29][  500/  782] loss: 0.515\n","[ep 29][  600/  782] loss: 0.529\n","[ep 29][  700/  782] loss: 0.360\n","[ep 30][  100/  782] loss: 0.579\n","[ep 30][  200/  782] loss: 0.548\n","[ep 30][  300/  782] loss: 0.581\n","[ep 30][  400/  782] loss: 0.762\n","[ep 30][  500/  782] loss: 0.491\n","[ep 30][  600/  782] loss: 0.700\n","[ep 30][  700/  782] loss: 0.413\n","[ep 31][  100/  782] loss: 0.338\n","[ep 31][  200/  782] loss: 0.474\n","[ep 31][  300/  782] loss: 0.826\n","[ep 31][  400/  782] loss: 0.441\n","[ep 31][  500/  782] loss: 0.482\n","[ep 31][  600/  782] loss: 0.343\n","[ep 31][  700/  782] loss: 0.512\n","[ep 32][  100/  782] loss: 0.337\n","[ep 32][  200/  782] loss: 0.573\n","[ep 32][  300/  782] loss: 0.427\n","[ep 32][  400/  782] loss: 0.399\n","[ep 32][  500/  782] loss: 0.316\n","[ep 32][  600/  782] loss: 0.829\n","[ep 32][  700/  782] loss: 0.433\n","[ep 33][  100/  782] loss: 0.352\n","[ep 33][  200/  782] loss: 0.372\n","[ep 33][  300/  782] loss: 0.453\n","[ep 33][  400/  782] loss: 0.433\n","[ep 33][  500/  782] loss: 0.482\n","[ep 33][  600/  782] loss: 0.373\n","[ep 33][  700/  782] loss: 0.503\n","[ep 34][  100/  782] loss: 0.405\n","[ep 34][  200/  782] loss: 0.279\n","[ep 34][  300/  782] loss: 0.422\n","[ep 34][  400/  782] loss: 0.306\n","[ep 34][  500/  782] loss: 0.478\n","[ep 34][  600/  782] loss: 0.363\n","[ep 34][  700/  782] loss: 0.335\n","[ep 35][  100/  782] loss: 0.460\n","[ep 35][  200/  782] loss: 0.290\n","[ep 35][  300/  782] loss: 0.347\n","[ep 35][  400/  782] loss: 0.342\n","[ep 35][  500/  782] loss: 0.407\n","[ep 35][  600/  782] loss: 0.402\n","[ep 35][  700/  782] loss: 0.453\n","[ep 36][  100/  782] loss: 0.427\n","[ep 36][  200/  782] loss: 0.515\n","[ep 36][  300/  782] loss: 0.382\n","[ep 36][  400/  782] loss: 0.395\n","[ep 36][  500/  782] loss: 0.434\n","[ep 36][  600/  782] loss: 0.570\n","[ep 36][  700/  782] loss: 0.337\n","[ep 37][  100/  782] loss: 0.341\n","[ep 37][  200/  782] loss: 0.365\n","[ep 37][  300/  782] loss: 0.369\n","[ep 37][  400/  782] loss: 0.210\n","[ep 37][  500/  782] loss: 0.334\n","[ep 37][  600/  782] loss: 0.329\n","[ep 37][  700/  782] loss: 0.320\n","[ep 38][  100/  782] loss: 0.306\n","[ep 38][  200/  782] loss: 0.327\n","[ep 38][  300/  782] loss: 0.366\n","[ep 38][  400/  782] loss: 0.255\n","[ep 38][  500/  782] loss: 0.348\n","[ep 38][  600/  782] loss: 0.336\n","[ep 38][  700/  782] loss: 0.546\n","[ep 39][  100/  782] loss: 0.279\n","[ep 39][  200/  782] loss: 0.345\n","[ep 39][  300/  782] loss: 0.393\n","[ep 39][  400/  782] loss: 0.322\n","[ep 39][  500/  782] loss: 0.197\n","[ep 39][  600/  782] loss: 0.273\n","[ep 39][  700/  782] loss: 0.382\n","[ep 40][  100/  782] loss: 0.286\n","[ep 40][  200/  782] loss: 0.261\n","[ep 40][  300/  782] loss: 0.300\n","[ep 40][  400/  782] loss: 0.286\n","[ep 40][  500/  782] loss: 0.292\n","[ep 40][  600/  782] loss: 0.368\n","[ep 40][  700/  782] loss: 0.261\n","[ep 41][  100/  782] loss: 0.309\n","[ep 41][  200/  782] loss: 0.243\n","[ep 41][  300/  782] loss: 0.219\n","[ep 41][  400/  782] loss: 0.362\n","[ep 41][  500/  782] loss: 0.285\n","[ep 41][  600/  782] loss: 0.335\n","[ep 41][  700/  782] loss: 0.315\n","[ep 42][  100/  782] loss: 0.313\n","[ep 42][  200/  782] loss: 0.173\n","[ep 42][  300/  782] loss: 0.230\n","[ep 42][  400/  782] loss: 0.222\n","[ep 42][  500/  782] loss: 0.252\n","[ep 42][  600/  782] loss: 0.275\n","[ep 42][  700/  782] loss: 0.161\n","[ep 43][  100/  782] loss: 0.110\n","[ep 43][  200/  782] loss: 0.185\n","[ep 43][  300/  782] loss: 0.203\n","[ep 43][  400/  782] loss: 0.207\n","[ep 43][  500/  782] loss: 0.189\n","[ep 43][  600/  782] loss: 0.294\n","[ep 43][  700/  782] loss: 0.316\n","[ep 44][  100/  782] loss: 0.192\n","[ep 44][  200/  782] loss: 0.226\n","[ep 44][  300/  782] loss: 0.246\n","[ep 44][  400/  782] loss: 0.198\n","[ep 44][  500/  782] loss: 0.319\n","[ep 44][  600/  782] loss: 0.261\n","[ep 44][  700/  782] loss: 0.230\n","[ep 45][  100/  782] loss: 0.218\n","[ep 45][  200/  782] loss: 0.173\n","[ep 45][  300/  782] loss: 0.348\n","[ep 45][  400/  782] loss: 0.213\n","[ep 45][  500/  782] loss: 0.162\n","[ep 45][  600/  782] loss: 0.256\n","[ep 45][  700/  782] loss: 0.193\n","[ep 46][  100/  782] loss: 0.205\n","[ep 46][  200/  782] loss: 0.204\n","[ep 46][  300/  782] loss: 0.177\n","[ep 46][  400/  782] loss: 0.210\n","[ep 46][  500/  782] loss: 0.159\n","[ep 46][  600/  782] loss: 0.256\n","[ep 46][  700/  782] loss: 0.123\n","[ep 47][  100/  782] loss: 0.202\n","[ep 47][  200/  782] loss: 0.179\n","[ep 47][  300/  782] loss: 0.129\n","[ep 47][  400/  782] loss: 0.157\n","[ep 47][  500/  782] loss: 0.150\n","[ep 47][  600/  782] loss: 0.175\n","[ep 47][  700/  782] loss: 0.134\n","[ep 48][  100/  782] loss: 0.112\n","[ep 48][  200/  782] loss: 0.108\n","[ep 48][  300/  782] loss: 0.163\n","[ep 48][  400/  782] loss: 0.120\n","[ep 48][  500/  782] loss: 0.202\n","[ep 48][  600/  782] loss: 0.096\n","[ep 48][  700/  782] loss: 0.171\n","[ep 49][  100/  782] loss: 0.143\n","[ep 49][  200/  782] loss: 0.128\n","[ep 49][  300/  782] loss: 0.192\n","[ep 49][  400/  782] loss: 0.192\n","[ep 49][  500/  782] loss: 0.116\n","[ep 49][  600/  782] loss: 0.294\n","[ep 49][  700/  782] loss: 0.193\n","[ep 50][  100/  782] loss: 0.202\n","[ep 50][  200/  782] loss: 0.073\n","[ep 50][  300/  782] loss: 0.250\n","[ep 50][  400/  782] loss: 0.098\n","[ep 50][  500/  782] loss: 0.138\n","[ep 50][  600/  782] loss: 0.122\n","[ep 50][  700/  782] loss: 0.120\n","[ep 51][  100/  782] loss: 0.145\n","[ep 51][  200/  782] loss: 0.089\n","[ep 51][  300/  782] loss: 0.076\n","[ep 51][  400/  782] loss: 0.169\n","[ep 51][  500/  782] loss: 0.076\n","[ep 51][  600/  782] loss: 0.179\n","[ep 51][  700/  782] loss: 0.101\n","[ep 52][  100/  782] loss: 0.123\n","[ep 52][  200/  782] loss: 0.146\n","[ep 52][  300/  782] loss: 0.093\n","[ep 52][  400/  782] loss: 0.074\n","[ep 52][  500/  782] loss: 0.142\n","[ep 52][  600/  782] loss: 0.164\n","[ep 52][  700/  782] loss: 0.086\n","[ep 53][  100/  782] loss: 0.111\n","[ep 53][  200/  782] loss: 0.108\n","[ep 53][  300/  782] loss: 0.116\n","[ep 53][  400/  782] loss: 0.222\n","[ep 53][  500/  782] loss: 0.177\n","[ep 53][  600/  782] loss: 0.092\n","[ep 53][  700/  782] loss: 0.201\n","[ep 54][  100/  782] loss: 0.174\n","[ep 54][  200/  782] loss: 0.069\n","[ep 54][  300/  782] loss: 0.136\n","[ep 54][  400/  782] loss: 0.062\n","[ep 54][  500/  782] loss: 0.184\n","[ep 54][  600/  782] loss: 0.161\n","[ep 54][  700/  782] loss: 0.092\n","[ep 55][  100/  782] loss: 0.097\n","[ep 55][  200/  782] loss: 0.129\n","[ep 55][  300/  782] loss: 0.099\n","[ep 55][  400/  782] loss: 0.067\n","[ep 55][  500/  782] loss: 0.136\n","[ep 55][  600/  782] loss: 0.097\n","[ep 55][  700/  782] loss: 0.074\n","[ep 56][  100/  782] loss: 0.060\n","[ep 56][  200/  782] loss: 0.133\n","[ep 56][  300/  782] loss: 0.069\n","[ep 56][  400/  782] loss: 0.120\n","[ep 56][  500/  782] loss: 0.063\n","[ep 56][  600/  782] loss: 0.119\n","[ep 56][  700/  782] loss: 0.126\n","[ep 57][  100/  782] loss: 0.109\n","[ep 57][  200/  782] loss: 0.142\n","[ep 57][  300/  782] loss: 0.090\n","[ep 57][  400/  782] loss: 0.075\n","[ep 57][  500/  782] loss: 0.040\n","[ep 57][  600/  782] loss: 0.078\n","[ep 57][  700/  782] loss: 0.093\n","[ep 58][  100/  782] loss: 0.097\n","[ep 58][  200/  782] loss: 0.104\n","[ep 58][  300/  782] loss: 0.071\n","[ep 58][  400/  782] loss: 0.107\n","[ep 58][  500/  782] loss: 0.080\n","[ep 58][  600/  782] loss: 0.102\n","[ep 58][  700/  782] loss: 0.145\n","[ep 59][  100/  782] loss: 0.109\n","[ep 59][  200/  782] loss: 0.107\n","[ep 59][  300/  782] loss: 0.059\n","[ep 59][  400/  782] loss: 0.076\n","[ep 59][  500/  782] loss: 0.072\n","[ep 59][  600/  782] loss: 0.169\n","[ep 59][  700/  782] loss: 0.098\n","[ep 60][  100/  782] loss: 0.087\n","[ep 60][  200/  782] loss: 0.077\n","[ep 60][  300/  782] loss: 0.101\n","[ep 60][  400/  782] loss: 0.074\n","[ep 60][  500/  782] loss: 0.078\n","[ep 60][  600/  782] loss: 0.094\n","[ep 60][  700/  782] loss: 0.140\n","[ep 61][  100/  782] loss: 0.067\n","[ep 61][  200/  782] loss: 0.064\n","[ep 61][  300/  782] loss: 0.077\n","[ep 61][  400/  782] loss: 0.061\n","[ep 61][  500/  782] loss: 0.076\n","[ep 61][  600/  782] loss: 0.090\n","[ep 61][  700/  782] loss: 0.096\n","[ep 62][  100/  782] loss: 0.056\n","[ep 62][  200/  782] loss: 0.099\n","[ep 62][  300/  782] loss: 0.094\n","[ep 62][  400/  782] loss: 0.077\n","[ep 62][  500/  782] loss: 0.054\n","[ep 62][  600/  782] loss: 0.048\n","[ep 62][  700/  782] loss: 0.042\n","[ep 63][  100/  782] loss: 0.099\n","[ep 63][  200/  782] loss: 0.041\n","[ep 63][  300/  782] loss: 0.057\n","[ep 63][  400/  782] loss: 0.101\n","[ep 63][  500/  782] loss: 0.050\n","[ep 63][  600/  782] loss: 0.114\n","[ep 63][  700/  782] loss: 0.041\n","[ep 64][  100/  782] loss: 0.044\n","[ep 64][  200/  782] loss: 0.059\n","[ep 64][  300/  782] loss: 0.091\n","[ep 64][  400/  782] loss: 0.077\n","[ep 64][  500/  782] loss: 0.049\n","[ep 64][  600/  782] loss: 0.073\n","[ep 64][  700/  782] loss: 0.044\n","[ep 65][  100/  782] loss: 0.088\n","[ep 65][  200/  782] loss: 0.034\n","[ep 65][  300/  782] loss: 0.079\n","[ep 65][  400/  782] loss: 0.094\n","[ep 65][  500/  782] loss: 0.028\n","[ep 65][  600/  782] loss: 0.043\n","[ep 65][  700/  782] loss: 0.056\n","[ep 66][  100/  782] loss: 0.068\n","[ep 66][  200/  782] loss: 0.051\n","[ep 66][  300/  782] loss: 0.042\n","[ep 66][  400/  782] loss: 0.057\n","[ep 66][  500/  782] loss: 0.069\n","[ep 66][  600/  782] loss: 0.040\n","[ep 66][  700/  782] loss: 0.154\n","[ep 67][  100/  782] loss: 0.078\n","[ep 67][  200/  782] loss: 0.081\n","[ep 67][  300/  782] loss: 0.074\n","[ep 67][  400/  782] loss: 0.023\n","[ep 67][  500/  782] loss: 0.065\n","[ep 67][  600/  782] loss: 0.053\n","[ep 67][  700/  782] loss: 0.062\n","[ep 68][  100/  782] loss: 0.096\n","[ep 68][  200/  782] loss: 0.027\n","[ep 68][  300/  782] loss: 0.148\n","[ep 68][  400/  782] loss: 0.067\n","[ep 68][  500/  782] loss: 0.030\n","[ep 68][  600/  782] loss: 0.059\n","[ep 68][  700/  782] loss: 0.042\n","[ep 69][  100/  782] loss: 0.025\n","[ep 69][  200/  782] loss: 0.038\n","[ep 69][  300/  782] loss: 0.087\n","[ep 69][  400/  782] loss: 0.029\n","[ep 69][  500/  782] loss: 0.067\n","[ep 69][  600/  782] loss: 0.034\n","[ep 69][  700/  782] loss: 0.057\n","[ep 70][  100/  782] loss: 0.027\n","[ep 70][  200/  782] loss: 0.038\n","[ep 70][  300/  782] loss: 0.035\n","[ep 70][  400/  782] loss: 0.039\n","[ep 70][  500/  782] loss: 0.062\n","[ep 70][  600/  782] loss: 0.048\n","[ep 70][  700/  782] loss: 0.064\n","[ep 71][  100/  782] loss: 0.047\n","[ep 71][  200/  782] loss: 0.036\n","[ep 71][  300/  782] loss: 0.051\n","[ep 71][  400/  782] loss: 0.033\n","[ep 71][  500/  782] loss: 0.062\n","[ep 71][  600/  782] loss: 0.067\n","[ep 71][  700/  782] loss: 0.045\n","[ep 72][  100/  782] loss: 0.025\n","[ep 72][  200/  782] loss: 0.024\n","[ep 72][  300/  782] loss: 0.044\n","[ep 72][  400/  782] loss: 0.030\n","[ep 72][  500/  782] loss: 0.035\n","[ep 72][  600/  782] loss: 0.031\n","[ep 72][  700/  782] loss: 0.037\n","[ep 73][  100/  782] loss: 0.031\n","[ep 73][  200/  782] loss: 0.039\n","[ep 73][  300/  782] loss: 0.055\n","[ep 73][  400/  782] loss: 0.041\n","[ep 73][  500/  782] loss: 0.055\n","[ep 73][  600/  782] loss: 0.042\n","[ep 73][  700/  782] loss: 0.072\n","[ep 74][  100/  782] loss: 0.054\n","[ep 74][  200/  782] loss: 0.051\n","[ep 74][  300/  782] loss: 0.118\n","[ep 74][  400/  782] loss: 0.033\n","[ep 74][  500/  782] loss: 0.030\n","[ep 74][  600/  782] loss: 0.032\n","[ep 74][  700/  782] loss: 0.041\n","[ep 75][  100/  782] loss: 0.052\n","[ep 75][  200/  782] loss: 0.032\n","[ep 75][  300/  782] loss: 0.026\n","[ep 75][  400/  782] loss: 0.075\n","[ep 75][  500/  782] loss: 0.035\n","[ep 75][  600/  782] loss: 0.050\n","[ep 75][  700/  782] loss: 0.038\n","[ep 76][  100/  782] loss: 0.027\n","[ep 76][  200/  782] loss: 0.022\n","[ep 76][  300/  782] loss: 0.033\n","[ep 76][  400/  782] loss: 0.032\n","[ep 76][  500/  782] loss: 0.053\n","[ep 76][  600/  782] loss: 0.031\n","[ep 76][  700/  782] loss: 0.031\n","[ep 77][  100/  782] loss: 0.027\n","[ep 77][  200/  782] loss: 0.023\n","[ep 77][  300/  782] loss: 0.072\n","[ep 77][  400/  782] loss: 0.021\n","[ep 77][  500/  782] loss: 0.019\n","[ep 77][  600/  782] loss: 0.043\n","[ep 77][  700/  782] loss: 0.020\n","[ep 78][  100/  782] loss: 0.022\n","[ep 78][  200/  782] loss: 0.032\n","[ep 78][  300/  782] loss: 0.043\n","[ep 78][  400/  782] loss: 0.023\n","[ep 78][  500/  782] loss: 0.048\n","[ep 78][  600/  782] loss: 0.030\n","[ep 78][  700/  782] loss: 0.062\n","[ep 79][  100/  782] loss: 0.024\n","[ep 79][  200/  782] loss: 0.111\n","[ep 79][  300/  782] loss: 0.041\n","[ep 79][  400/  782] loss: 0.039\n","[ep 79][  500/  782] loss: 0.046\n","[ep 79][  600/  782] loss: 0.024\n","[ep 79][  700/  782] loss: 0.053\n","[ep 80][  100/  782] loss: 0.012\n","[ep 80][  200/  782] loss: 0.033\n","[ep 80][  300/  782] loss: 0.015\n","[ep 80][  400/  782] loss: 0.015\n","[ep 80][  500/  782] loss: 0.037\n","[ep 80][  600/  782] loss: 0.040\n","[ep 80][  700/  782] loss: 0.028\n","[ep 81][  100/  782] loss: 0.031\n","[ep 81][  200/  782] loss: 0.046\n","[ep 81][  300/  782] loss: 0.049\n","[ep 81][  400/  782] loss: 0.022\n","[ep 81][  500/  782] loss: 0.022\n","[ep 81][  600/  782] loss: 0.037\n","[ep 81][  700/  782] loss: 0.023\n","[ep 82][  100/  782] loss: 0.026\n","[ep 82][  200/  782] loss: 0.043\n","[ep 82][  300/  782] loss: 0.021\n","[ep 82][  400/  782] loss: 0.112\n","[ep 82][  500/  782] loss: 0.014\n","[ep 82][  600/  782] loss: 0.033\n","[ep 82][  700/  782] loss: 0.025\n","[ep 83][  100/  782] loss: 0.020\n","[ep 83][  200/  782] loss: 0.034\n","[ep 83][  300/  782] loss: 0.018\n","[ep 83][  400/  782] loss: 0.022\n","[ep 83][  500/  782] loss: 0.014\n","[ep 83][  600/  782] loss: 0.032\n","[ep 83][  700/  782] loss: 0.026\n","[ep 84][  100/  782] loss: 0.016\n","[ep 84][  200/  782] loss: 0.034\n","[ep 84][  300/  782] loss: 0.020\n","[ep 84][  400/  782] loss: 0.026\n","[ep 84][  500/  782] loss: 0.027\n","[ep 84][  600/  782] loss: 0.025\n","[ep 84][  700/  782] loss: 0.050\n","[ep 85][  100/  782] loss: 0.027\n","[ep 85][  200/  782] loss: 0.014\n","[ep 85][  300/  782] loss: 0.027\n","[ep 85][  400/  782] loss: 0.038\n","[ep 85][  500/  782] loss: 0.079\n","[ep 85][  600/  782] loss: 0.050\n","[ep 85][  700/  782] loss: 0.027\n","[ep 86][  100/  782] loss: 0.028\n","[ep 86][  200/  782] loss: 0.026\n","[ep 86][  300/  782] loss: 0.023\n","[ep 86][  400/  782] loss: 0.025\n","[ep 86][  500/  782] loss: 0.022\n","[ep 86][  600/  782] loss: 0.034\n","[ep 86][  700/  782] loss: 0.019\n","[ep 87][  100/  782] loss: 0.017\n","[ep 87][  200/  782] loss: 0.021\n","[ep 87][  300/  782] loss: 0.026\n","[ep 87][  400/  782] loss: 0.012\n","[ep 87][  500/  782] loss: 0.028\n","[ep 87][  600/  782] loss: 0.036\n","[ep 87][  700/  782] loss: 0.023\n","[ep 88][  100/  782] loss: 0.016\n","[ep 88][  200/  782] loss: 0.037\n","[ep 88][  300/  782] loss: 0.049\n","[ep 88][  400/  782] loss: 0.015\n","[ep 88][  500/  782] loss: 0.013\n","[ep 88][  600/  782] loss: 0.014\n","[ep 88][  700/  782] loss: 0.015\n","[ep 89][  100/  782] loss: 0.025\n","[ep 89][  200/  782] loss: 0.016\n","[ep 89][  300/  782] loss: 0.018\n","[ep 89][  400/  782] loss: 0.028\n","[ep 89][  500/  782] loss: 0.047\n","[ep 89][  600/  782] loss: 0.028\n","[ep 89][  700/  782] loss: 0.035\n","[ep 90][  100/  782] loss: 0.019\n","[ep 90][  200/  782] loss: 0.022\n","[ep 90][  300/  782] loss: 0.014\n","[ep 90][  400/  782] loss: 0.033\n","[ep 90][  500/  782] loss: 0.019\n","[ep 90][  600/  782] loss: 0.017\n","[ep 90][  700/  782] loss: 0.012\n","[ep 91][  100/  782] loss: 0.019\n","[ep 91][  200/  782] loss: 0.025\n","[ep 91][  300/  782] loss: 0.018\n","[ep 91][  400/  782] loss: 0.016\n","[ep 91][  500/  782] loss: 0.023\n","[ep 91][  600/  782] loss: 0.045\n","[ep 91][  700/  782] loss: 0.036\n","[ep 92][  100/  782] loss: 0.013\n","[ep 92][  200/  782] loss: 0.024\n","[ep 92][  300/  782] loss: 0.027\n","[ep 92][  400/  782] loss: 0.024\n","[ep 92][  500/  782] loss: 0.022\n","[ep 92][  600/  782] loss: 0.023\n","[ep 92][  700/  782] loss: 0.033\n","[ep 93][  100/  782] loss: 0.021\n","[ep 93][  200/  782] loss: 0.016\n","[ep 93][  300/  782] loss: 0.018\n","[ep 93][  400/  782] loss: 0.011\n","[ep 93][  500/  782] loss: 0.077\n","[ep 93][  600/  782] loss: 0.017\n","[ep 93][  700/  782] loss: 0.027\n","[ep 94][  100/  782] loss: 0.021\n","[ep 94][  200/  782] loss: 0.024\n","[ep 94][  300/  782] loss: 0.026\n","[ep 94][  400/  782] loss: 0.021\n","[ep 94][  500/  782] loss: 0.013\n","[ep 94][  600/  782] loss: 0.010\n","[ep 94][  700/  782] loss: 0.020\n","[ep 95][  100/  782] loss: 0.019\n","[ep 95][  200/  782] loss: 0.019\n","[ep 95][  300/  782] loss: 0.051\n","[ep 95][  400/  782] loss: 0.018\n","[ep 95][  500/  782] loss: 0.016\n","[ep 95][  600/  782] loss: 0.021\n","[ep 95][  700/  782] loss: 0.017\n","[ep 96][  100/  782] loss: 0.017\n","[ep 96][  200/  782] loss: 0.015\n","[ep 96][  300/  782] loss: 0.024\n","[ep 96][  400/  782] loss: 0.012\n","[ep 96][  500/  782] loss: 0.013\n","[ep 96][  600/  782] loss: 0.012\n","[ep 96][  700/  782] loss: 0.017\n","[ep 97][  100/  782] loss: 0.030\n","[ep 97][  200/  782] loss: 0.013\n","[ep 97][  300/  782] loss: 0.040\n","[ep 97][  400/  782] loss: 0.019\n","[ep 97][  500/  782] loss: 0.034\n","[ep 97][  600/  782] loss: 0.010\n","[ep 97][  700/  782] loss: 0.016\n","[ep 98][  100/  782] loss: 0.023\n","[ep 98][  200/  782] loss: 0.018\n","[ep 98][  300/  782] loss: 0.011\n","[ep 98][  400/  782] loss: 0.012\n","[ep 98][  500/  782] loss: 0.021\n","[ep 98][  600/  782] loss: 0.012\n","[ep 98][  700/  782] loss: 0.020\n","[ep 99][  100/  782] loss: 0.027\n","[ep 99][  200/  782] loss: 0.009\n","[ep 99][  300/  782] loss: 0.015\n","[ep 99][  400/  782] loss: 0.018\n","[ep 99][  500/  782] loss: 0.008\n","[ep 99][  600/  782] loss: 0.012\n","[ep 99][  700/  782] loss: 0.009\n","[ep 100][  100/  782] loss: 0.021\n","[ep 100][  200/  782] loss: 0.015\n","[ep 100][  300/  782] loss: 0.024\n","[ep 100][  400/  782] loss: 0.029\n","[ep 100][  500/  782] loss: 0.013\n","[ep 100][  600/  782] loss: 0.040\n","[ep 100][  700/  782] loss: 0.009\n","[ep 101][  100/  782] loss: 0.032\n","[ep 101][  200/  782] loss: 0.020\n","[ep 101][  300/  782] loss: 0.019\n","[ep 101][  400/  782] loss: 0.036\n","[ep 101][  500/  782] loss: 0.017\n","[ep 101][  600/  782] loss: 0.018\n","[ep 101][  700/  782] loss: 0.021\n","[ep 102][  100/  782] loss: 0.010\n","[ep 102][  200/  782] loss: 0.009\n","[ep 102][  300/  782] loss: 0.046\n","[ep 102][  400/  782] loss: 0.014\n","[ep 102][  500/  782] loss: 0.018\n","[ep 102][  600/  782] loss: 0.012\n","[ep 102][  700/  782] loss: 0.050\n","[ep 103][  100/  782] loss: 0.014\n","[ep 103][  200/  782] loss: 0.017\n","[ep 103][  300/  782] loss: 0.009\n","[ep 103][  400/  782] loss: 0.007\n","[ep 103][  500/  782] loss: 0.014\n","[ep 103][  600/  782] loss: 0.008\n","[ep 103][  700/  782] loss: 0.018\n","[ep 104][  100/  782] loss: 0.094\n","[ep 104][  200/  782] loss: 0.010\n","[ep 104][  300/  782] loss: 0.018\n","[ep 104][  400/  782] loss: 0.012\n","[ep 104][  500/  782] loss: 0.011\n","[ep 104][  600/  782] loss: 0.017\n","[ep 104][  700/  782] loss: 0.012\n","[ep 105][  100/  782] loss: 0.014\n","[ep 105][  200/  782] loss: 0.014\n","[ep 105][  300/  782] loss: 0.010\n","[ep 105][  400/  782] loss: 0.017\n","[ep 105][  500/  782] loss: 0.025\n","[ep 105][  600/  782] loss: 0.025\n","[ep 105][  700/  782] loss: 0.014\n","[ep 106][  100/  782] loss: 0.039\n","[ep 106][  200/  782] loss: 0.021\n","[ep 106][  300/  782] loss: 0.011\n","[ep 106][  400/  782] loss: 0.017\n","[ep 106][  500/  782] loss: 0.006\n","[ep 106][  600/  782] loss: 0.034\n","[ep 106][  700/  782] loss: 0.018\n","[ep 107][  100/  782] loss: 0.038\n","[ep 107][  200/  782] loss: 0.016\n","[ep 107][  300/  782] loss: 0.007\n","[ep 107][  400/  782] loss: 0.014\n","[ep 107][  500/  782] loss: 0.035\n","[ep 107][  600/  782] loss: 0.008\n","[ep 107][  700/  782] loss: 0.010\n","[ep 108][  100/  782] loss: 0.013\n","[ep 108][  200/  782] loss: 0.007\n","[ep 108][  300/  782] loss: 0.011\n","[ep 108][  400/  782] loss: 0.012\n","[ep 108][  500/  782] loss: 0.011\n","[ep 108][  600/  782] loss: 0.011\n","[ep 108][  700/  782] loss: 0.018\n","[ep 109][  100/  782] loss: 0.010\n","[ep 109][  200/  782] loss: 0.013\n","[ep 109][  300/  782] loss: 0.016\n","[ep 109][  400/  782] loss: 0.032\n","[ep 109][  500/  782] loss: 0.011\n","[ep 109][  600/  782] loss: 0.008\n","[ep 109][  700/  782] loss: 0.017\n","[ep 110][  100/  782] loss: 0.015\n","[ep 110][  200/  782] loss: 0.017\n","[ep 110][  300/  782] loss: 0.015\n","[ep 110][  400/  782] loss: 0.028\n","[ep 110][  500/  782] loss: 0.015\n","[ep 110][  600/  782] loss: 0.016\n","[ep 110][  700/  782] loss: 0.016\n","[ep 111][  100/  782] loss: 0.011\n","[ep 111][  200/  782] loss: 0.012\n","[ep 111][  300/  782] loss: 0.020\n","[ep 111][  400/  782] loss: 0.016\n","[ep 111][  500/  782] loss: 0.019\n","[ep 111][  600/  782] loss: 0.017\n","[ep 111][  700/  782] loss: 0.021\n","[ep 112][  100/  782] loss: 0.016\n","[ep 112][  200/  782] loss: 0.020\n","[ep 112][  300/  782] loss: 0.007\n","[ep 112][  400/  782] loss: 0.012\n","[ep 112][  500/  782] loss: 0.013\n","[ep 112][  600/  782] loss: 0.036\n","[ep 112][  700/  782] loss: 0.012\n","[ep 113][  100/  782] loss: 0.009\n","[ep 113][  200/  782] loss: 0.010\n","[ep 113][  300/  782] loss: 0.008\n","[ep 113][  400/  782] loss: 0.023\n","[ep 113][  500/  782] loss: 0.010\n","[ep 113][  600/  782] loss: 0.022\n","[ep 113][  700/  782] loss: 0.015\n","[ep 114][  100/  782] loss: 0.009\n","[ep 114][  200/  782] loss: 0.016\n","[ep 114][  300/  782] loss: 0.017\n","[ep 114][  400/  782] loss: 0.015\n","[ep 114][  500/  782] loss: 0.008\n","[ep 114][  600/  782] loss: 0.018\n","[ep 114][  700/  782] loss: 0.013\n","[ep 115][  100/  782] loss: 0.012\n","[ep 115][  200/  782] loss: 0.042\n","[ep 115][  300/  782] loss: 0.005\n","[ep 115][  400/  782] loss: 0.007\n","[ep 115][  500/  782] loss: 0.026\n","[ep 115][  600/  782] loss: 0.048\n","[ep 115][  700/  782] loss: 0.006\n","[ep 116][  100/  782] loss: 0.012\n","[ep 116][  200/  782] loss: 0.015\n","[ep 116][  300/  782] loss: 0.007\n","[ep 116][  400/  782] loss: 0.008\n","[ep 116][  500/  782] loss: 0.008\n","[ep 116][  600/  782] loss: 0.008\n","[ep 116][  700/  782] loss: 0.030\n","[ep 117][  100/  782] loss: 0.018\n","[ep 117][  200/  782] loss: 0.008\n","[ep 117][  300/  782] loss: 0.008\n","[ep 117][  400/  782] loss: 0.008\n","[ep 117][  500/  782] loss: 0.018\n","[ep 117][  600/  782] loss: 0.009\n","[ep 117][  700/  782] loss: 0.027\n","[ep 118][  100/  782] loss: 0.007\n","[ep 118][  200/  782] loss: 0.010\n","[ep 118][  300/  782] loss: 0.011\n","[ep 118][  400/  782] loss: 0.007\n","[ep 118][  500/  782] loss: 0.011\n","[ep 118][  600/  782] loss: 0.007\n","[ep 118][  700/  782] loss: 0.012\n","[ep 119][  100/  782] loss: 0.006\n","[ep 119][  200/  782] loss: 0.011\n","[ep 119][  300/  782] loss: 0.008\n","[ep 119][  400/  782] loss: 0.012\n","[ep 119][  500/  782] loss: 0.011\n","[ep 119][  600/  782] loss: 0.012\n","[ep 119][  700/  782] loss: 0.010\n","[ep 120][  100/  782] loss: 0.021\n","[ep 120][  200/  782] loss: 0.027\n","[ep 120][  300/  782] loss: 0.010\n","[ep 120][  400/  782] loss: 0.010\n","[ep 120][  500/  782] loss: 0.018\n","[ep 120][  600/  782] loss: 0.046\n","[ep 120][  700/  782] loss: 0.012\n","[ep 121][  100/  782] loss: 0.007\n","[ep 121][  200/  782] loss: 0.007\n","[ep 121][  300/  782] loss: 0.011\n","[ep 121][  400/  782] loss: 0.033\n","[ep 121][  500/  782] loss: 0.008\n","[ep 121][  600/  782] loss: 0.019\n","[ep 121][  700/  782] loss: 0.008\n","[ep 122][  100/  782] loss: 0.007\n","[ep 122][  200/  782] loss: 0.011\n","[ep 122][  300/  782] loss: 0.022\n","[ep 122][  400/  782] loss: 0.007\n","[ep 122][  500/  782] loss: 0.017\n","[ep 122][  600/  782] loss: 0.009\n","[ep 122][  700/  782] loss: 0.009\n","[ep 123][  100/  782] loss: 0.075\n","[ep 123][  200/  782] loss: 0.014\n","[ep 123][  300/  782] loss: 0.010\n","[ep 123][  400/  782] loss: 0.009\n","[ep 123][  500/  782] loss: 0.007\n","[ep 123][  600/  782] loss: 0.030\n","[ep 123][  700/  782] loss: 0.007\n","[ep 124][  100/  782] loss: 0.005\n","[ep 124][  200/  782] loss: 0.027\n","[ep 124][  300/  782] loss: 0.015\n","[ep 124][  400/  782] loss: 0.006\n","[ep 124][  500/  782] loss: 0.005\n","[ep 124][  600/  782] loss: 0.012\n","[ep 124][  700/  782] loss: 0.021\n","[ep 125][  100/  782] loss: 0.004\n","[ep 125][  200/  782] loss: 0.011\n","[ep 125][  300/  782] loss: 0.004\n","[ep 125][  400/  782] loss: 0.008\n","[ep 125][  500/  782] loss: 0.008\n","[ep 125][  600/  782] loss: 0.008\n","[ep 125][  700/  782] loss: 0.009\n","[ep 126][  100/  782] loss: 0.007\n","[ep 126][  200/  782] loss: 0.007\n","[ep 126][  300/  782] loss: 0.012\n","[ep 126][  400/  782] loss: 0.010\n","[ep 126][  500/  782] loss: 0.008\n","[ep 126][  600/  782] loss: 0.009\n","[ep 126][  700/  782] loss: 0.006\n","[ep 127][  100/  782] loss: 0.006\n","[ep 127][  200/  782] loss: 0.011\n","[ep 127][  300/  782] loss: 0.009\n","[ep 127][  400/  782] loss: 0.006\n","[ep 127][  500/  782] loss: 0.025\n","[ep 127][  600/  782] loss: 0.010\n","[ep 127][  700/  782] loss: 0.006\n","[ep 128][  100/  782] loss: 0.013\n","[ep 128][  200/  782] loss: 0.011\n","[ep 128][  300/  782] loss: 0.014\n","[ep 128][  400/  782] loss: 0.006\n","[ep 128][  500/  782] loss: 0.019\n","[ep 128][  600/  782] loss: 0.007\n","[ep 128][  700/  782] loss: 0.008\n","[ep 129][  100/  782] loss: 0.006\n","[ep 129][  200/  782] loss: 0.046\n","[ep 129][  300/  782] loss: 0.013\n","[ep 129][  400/  782] loss: 0.012\n","[ep 129][  500/  782] loss: 0.004\n","[ep 129][  600/  782] loss: 0.009\n","[ep 129][  700/  782] loss: 0.011\n","[ep 130][  100/  782] loss: 0.012\n","[ep 130][  200/  782] loss: 0.013\n","[ep 130][  300/  782] loss: 0.009\n","[ep 130][  400/  782] loss: 0.010\n","[ep 130][  500/  782] loss: 0.007\n","[ep 130][  600/  782] loss: 0.042\n","[ep 130][  700/  782] loss: 0.006\n","[ep 131][  100/  782] loss: 0.006\n","[ep 131][  200/  782] loss: 0.010\n","[ep 131][  300/  782] loss: 0.010\n","[ep 131][  400/  782] loss: 0.011\n","[ep 131][  500/  782] loss: 0.008\n","[ep 131][  600/  782] loss: 0.012\n","[ep 131][  700/  782] loss: 0.010\n","[ep 132][  100/  782] loss: 0.013\n","[ep 132][  200/  782] loss: 0.007\n","[ep 132][  300/  782] loss: 0.007\n","[ep 132][  400/  782] loss: 0.012\n","[ep 132][  500/  782] loss: 0.012\n","[ep 132][  600/  782] loss: 0.010\n","[ep 132][  700/  782] loss: 0.007\n","[ep 133][  100/  782] loss: 0.013\n","[ep 133][  200/  782] loss: 0.016\n","[ep 133][  300/  782] loss: 0.008\n","[ep 133][  400/  782] loss: 0.013\n","[ep 133][  500/  782] loss: 0.009\n","[ep 133][  600/  782] loss: 0.008\n","[ep 133][  700/  782] loss: 0.017\n","[ep 134][  100/  782] loss: 0.007\n","[ep 134][  200/  782] loss: 0.020\n","[ep 134][  300/  782] loss: 0.005\n","[ep 134][  400/  782] loss: 0.007\n","[ep 134][  500/  782] loss: 0.016\n","[ep 134][  600/  782] loss: 0.012\n","[ep 134][  700/  782] loss: 0.004\n","[ep 135][  100/  782] loss: 0.011\n","[ep 135][  200/  782] loss: 0.011\n","[ep 135][  300/  782] loss: 0.006\n","[ep 135][  400/  782] loss: 0.007\n","[ep 135][  500/  782] loss: 0.008\n","[ep 135][  600/  782] loss: 0.009\n","[ep 135][  700/  782] loss: 0.006\n","[ep 136][  100/  782] loss: 0.010\n","[ep 136][  200/  782] loss: 0.007\n","[ep 136][  300/  782] loss: 0.008\n","[ep 136][  400/  782] loss: 0.003\n","[ep 136][  500/  782] loss: 0.011\n","[ep 136][  600/  782] loss: 0.006\n","[ep 136][  700/  782] loss: 0.010\n","[ep 137][  100/  782] loss: 0.005\n","[ep 137][  200/  782] loss: 0.010\n","[ep 137][  300/  782] loss: 0.011\n","[ep 137][  400/  782] loss: 0.013\n","[ep 137][  500/  782] loss: 0.011\n","[ep 137][  600/  782] loss: 0.006\n","[ep 137][  700/  782] loss: 0.037\n","[ep 138][  100/  782] loss: 0.011\n","[ep 138][  200/  782] loss: 0.005\n","[ep 138][  300/  782] loss: 0.008\n","[ep 138][  400/  782] loss: 0.004\n","[ep 138][  500/  782] loss: 0.010\n","[ep 138][  600/  782] loss: 0.005\n","[ep 138][  700/  782] loss: 0.008\n","[ep 139][  100/  782] loss: 0.007\n","[ep 139][  200/  782] loss: 0.010\n","[ep 139][  300/  782] loss: 0.004\n","[ep 139][  400/  782] loss: 0.011\n","[ep 139][  500/  782] loss: 0.014\n","[ep 139][  600/  782] loss: 0.005\n","[ep 139][  700/  782] loss: 0.006\n","[ep 140][  100/  782] loss: 0.005\n","[ep 140][  200/  782] loss: 0.009\n","[ep 140][  300/  782] loss: 0.012\n","[ep 140][  400/  782] loss: 0.007\n","[ep 140][  500/  782] loss: 0.003\n","[ep 140][  600/  782] loss: 0.007\n","[ep 140][  700/  782] loss: 0.003\n","[ep 141][  100/  782] loss: 0.008\n","[ep 141][  200/  782] loss: 0.006\n","[ep 141][  300/  782] loss: 0.013\n","[ep 141][  400/  782] loss: 0.008\n","[ep 141][  500/  782] loss: 0.008\n","[ep 141][  600/  782] loss: 0.011\n","[ep 141][  700/  782] loss: 0.005\n","[ep 142][  100/  782] loss: 0.004\n","[ep 142][  200/  782] loss: 0.005\n","[ep 142][  300/  782] loss: 0.008\n","[ep 142][  400/  782] loss: 0.017\n","[ep 142][  500/  782] loss: 0.019\n","[ep 142][  600/  782] loss: 0.004\n","[ep 142][  700/  782] loss: 0.018\n","[ep 143][  100/  782] loss: 0.003\n","[ep 143][  200/  782] loss: 0.012\n","[ep 143][  300/  782] loss: 0.008\n","[ep 143][  400/  782] loss: 0.011\n","[ep 143][  500/  782] loss: 0.006\n","[ep 143][  600/  782] loss: 0.005\n","[ep 143][  700/  782] loss: 0.023\n","[ep 144][  100/  782] loss: 0.011\n","[ep 144][  200/  782] loss: 0.011\n","[ep 144][  300/  782] loss: 0.010\n","[ep 144][  400/  782] loss: 0.004\n","[ep 144][  500/  782] loss: 0.003\n","[ep 144][  600/  782] loss: 0.009\n","[ep 144][  700/  782] loss: 0.006\n","[ep 145][  100/  782] loss: 0.010\n","[ep 145][  200/  782] loss: 0.010\n","[ep 145][  300/  782] loss: 0.022\n","[ep 145][  400/  782] loss: 0.018\n","[ep 145][  500/  782] loss: 0.008\n","[ep 145][  600/  782] loss: 0.011\n","[ep 145][  700/  782] loss: 0.010\n","[ep 146][  100/  782] loss: 0.005\n","[ep 146][  200/  782] loss: 0.025\n","[ep 146][  300/  782] loss: 0.005\n","[ep 146][  400/  782] loss: 0.006\n","[ep 146][  500/  782] loss: 0.007\n","[ep 146][  600/  782] loss: 0.008\n","[ep 146][  700/  782] loss: 0.004\n","[ep 147][  100/  782] loss: 0.004\n","[ep 147][  200/  782] loss: 0.004\n","[ep 147][  300/  782] loss: 0.003\n","[ep 147][  400/  782] loss: 0.007\n","[ep 147][  500/  782] loss: 0.003\n","[ep 147][  600/  782] loss: 0.006\n","[ep 147][  700/  782] loss: 0.005\n","[ep 148][  100/  782] loss: 0.008\n","[ep 148][  200/  782] loss: 0.019\n","[ep 148][  300/  782] loss: 0.036\n","[ep 148][  400/  782] loss: 0.005\n","[ep 148][  500/  782] loss: 0.011\n","[ep 148][  600/  782] loss: 0.005\n","[ep 148][  700/  782] loss: 0.003\n","[ep 149][  100/  782] loss: 0.006\n","[ep 149][  200/  782] loss: 0.007\n","[ep 149][  300/  782] loss: 0.005\n","[ep 149][  400/  782] loss: 0.004\n","[ep 149][  500/  782] loss: 0.004\n","[ep 149][  600/  782] loss: 0.005\n","[ep 149][  700/  782] loss: 0.006\n","[ep 150][  100/  782] loss: 0.007\n","[ep 150][  200/  782] loss: 0.004\n","[ep 150][  300/  782] loss: 0.017\n","[ep 150][  400/  782] loss: 0.005\n","[ep 150][  500/  782] loss: 0.003\n","[ep 150][  600/  782] loss: 0.007\n","[ep 150][  700/  782] loss: 0.009\n","[ep 151][  100/  782] loss: 0.013\n","[ep 151][  200/  782] loss: 0.004\n","[ep 151][  300/  782] loss: 0.007\n","[ep 151][  400/  782] loss: 0.016\n","[ep 151][  500/  782] loss: 0.005\n","[ep 151][  600/  782] loss: 0.005\n","[ep 151][  700/  782] loss: 0.006\n","[ep 152][  100/  782] loss: 0.007\n","[ep 152][  200/  782] loss: 0.026\n","[ep 152][  300/  782] loss: 0.003\n","[ep 152][  400/  782] loss: 0.005\n","[ep 152][  500/  782] loss: 0.008\n","[ep 152][  600/  782] loss: 0.015\n","[ep 152][  700/  782] loss: 0.007\n","[ep 153][  100/  782] loss: 0.004\n","[ep 153][  200/  782] loss: 0.005\n","[ep 153][  300/  782] loss: 0.011\n","[ep 153][  400/  782] loss: 0.013\n","[ep 153][  500/  782] loss: 0.014\n","[ep 153][  600/  782] loss: 0.009\n","[ep 153][  700/  782] loss: 0.004\n","[ep 154][  100/  782] loss: 0.004\n","[ep 154][  200/  782] loss: 0.008\n","[ep 154][  300/  782] loss: 0.003\n","[ep 154][  400/  782] loss: 0.006\n","[ep 154][  500/  782] loss: 0.008\n","[ep 154][  600/  782] loss: 0.006\n","[ep 154][  700/  782] loss: 0.010\n","[ep 155][  100/  782] loss: 0.006\n","[ep 155][  200/  782] loss: 0.008\n","[ep 155][  300/  782] loss: 0.005\n","[ep 155][  400/  782] loss: 0.007\n","[ep 155][  500/  782] loss: 0.005\n","[ep 155][  600/  782] loss: 0.004\n","[ep 155][  700/  782] loss: 0.004\n","[ep 156][  100/  782] loss: 0.010\n","[ep 156][  200/  782] loss: 0.008\n","[ep 156][  300/  782] loss: 0.009\n","[ep 156][  400/  782] loss: 0.005\n","[ep 156][  500/  782] loss: 0.007\n","[ep 156][  600/  782] loss: 0.003\n","[ep 156][  700/  782] loss: 0.004\n","[ep 157][  100/  782] loss: 0.015\n","[ep 157][  200/  782] loss: 0.008\n","[ep 157][  300/  782] loss: 0.005\n","[ep 157][  400/  782] loss: 0.005\n","[ep 157][  500/  782] loss: 0.006\n","[ep 157][  600/  782] loss: 0.009\n","[ep 157][  700/  782] loss: 0.010\n","[ep 158][  100/  782] loss: 0.004\n","[ep 158][  200/  782] loss: 0.019\n","[ep 158][  300/  782] loss: 0.007\n","[ep 158][  400/  782] loss: 0.013\n","[ep 158][  500/  782] loss: 0.005\n","[ep 158][  600/  782] loss: 0.004\n","[ep 158][  700/  782] loss: 0.008\n","[ep 159][  100/  782] loss: 0.006\n","[ep 159][  200/  782] loss: 0.003\n","[ep 159][  300/  782] loss: 0.007\n","[ep 159][  400/  782] loss: 0.003\n","[ep 159][  500/  782] loss: 0.010\n","[ep 159][  600/  782] loss: 0.004\n","[ep 159][  700/  782] loss: 0.007\n","[ep 160][  100/  782] loss: 0.009\n","[ep 160][  200/  782] loss: 0.019\n","[ep 160][  300/  782] loss: 0.025\n","[ep 160][  400/  782] loss: 0.004\n","[ep 160][  500/  782] loss: 0.008\n","[ep 160][  600/  782] loss: 0.010\n","[ep 160][  700/  782] loss: 0.008\n","[ep 161][  100/  782] loss: 0.003\n","[ep 161][  200/  782] loss: 0.004\n","[ep 161][  300/  782] loss: 0.004\n","[ep 161][  400/  782] loss: 0.005\n","[ep 161][  500/  782] loss: 0.005\n","[ep 161][  600/  782] loss: 0.006\n","[ep 161][  700/  782] loss: 0.004\n","[ep 162][  100/  782] loss: 0.002\n","[ep 162][  200/  782] loss: 0.003\n","[ep 162][  300/  782] loss: 0.005\n","[ep 162][  400/  782] loss: 0.009\n","[ep 162][  500/  782] loss: 0.006\n","[ep 162][  600/  782] loss: 0.004\n","[ep 162][  700/  782] loss: 0.003\n","[ep 163][  100/  782] loss: 0.005\n","[ep 163][  200/  782] loss: 0.005\n","[ep 163][  300/  782] loss: 0.007\n","[ep 163][  400/  782] loss: 0.003\n","[ep 163][  500/  782] loss: 0.005\n","[ep 163][  600/  782] loss: 0.006\n","[ep 163][  700/  782] loss: 0.008\n","[ep 164][  100/  782] loss: 0.008\n","[ep 164][  200/  782] loss: 0.033\n","[ep 164][  300/  782] loss: 0.005\n","[ep 164][  400/  782] loss: 0.004\n","[ep 164][  500/  782] loss: 0.013\n","[ep 164][  600/  782] loss: 0.034\n","[ep 164][  700/  782] loss: 0.028\n","[ep 165][  100/  782] loss: 0.004\n","[ep 165][  200/  782] loss: 0.004\n","[ep 165][  300/  782] loss: 0.009\n","[ep 165][  400/  782] loss: 0.005\n","[ep 165][  500/  782] loss: 0.005\n","[ep 165][  600/  782] loss: 0.004\n","[ep 165][  700/  782] loss: 0.006\n","[ep 166][  100/  782] loss: 0.003\n","[ep 166][  200/  782] loss: 0.003\n","[ep 166][  300/  782] loss: 0.003\n","[ep 166][  400/  782] loss: 0.009\n","[ep 166][  500/  782] loss: 0.004\n","[ep 166][  600/  782] loss: 0.005\n","[ep 166][  700/  782] loss: 0.003\n","[ep 167][  100/  782] loss: 0.005\n","[ep 167][  200/  782] loss: 0.006\n","[ep 167][  300/  782] loss: 0.004\n","[ep 167][  400/  782] loss: 0.006\n","[ep 167][  500/  782] loss: 0.002\n","[ep 167][  600/  782] loss: 0.008\n","[ep 167][  700/  782] loss: 0.007\n","[ep 168][  100/  782] loss: 0.007\n","[ep 168][  200/  782] loss: 0.010\n","[ep 168][  300/  782] loss: 0.006\n","[ep 168][  400/  782] loss: 0.010\n","[ep 168][  500/  782] loss: 0.019\n","[ep 168][  600/  782] loss: 0.006\n","[ep 168][  700/  782] loss: 0.013\n","[ep 169][  100/  782] loss: 0.005\n","[ep 169][  200/  782] loss: 0.003\n","[ep 169][  300/  782] loss: 0.004\n","[ep 169][  400/  782] loss: 0.004\n","[ep 169][  500/  782] loss: 0.013\n","[ep 169][  600/  782] loss: 0.003\n","[ep 169][  700/  782] loss: 0.003\n","[ep 170][  100/  782] loss: 0.005\n","[ep 170][  200/  782] loss: 0.006\n","[ep 170][  300/  782] loss: 0.008\n","[ep 170][  400/  782] loss: 0.003\n","[ep 170][  500/  782] loss: 0.005\n","[ep 170][  600/  782] loss: 0.011\n","[ep 170][  700/  782] loss: 0.018\n","[ep 171][  100/  782] loss: 0.007\n","[ep 171][  200/  782] loss: 0.005\n","[ep 171][  300/  782] loss: 0.007\n","[ep 171][  400/  782] loss: 0.003\n","[ep 171][  500/  782] loss: 0.006\n","[ep 171][  600/  782] loss: 0.004\n","[ep 171][  700/  782] loss: 0.004\n","[ep 172][  100/  782] loss: 0.005\n","[ep 172][  200/  782] loss: 0.010\n","[ep 172][  300/  782] loss: 0.003\n","[ep 172][  400/  782] loss: 0.004\n","[ep 172][  500/  782] loss: 0.003\n","[ep 172][  600/  782] loss: 0.003\n","[ep 172][  700/  782] loss: 0.004\n","[ep 173][  100/  782] loss: 0.005\n","[ep 173][  200/  782] loss: 0.002\n","[ep 173][  300/  782] loss: 0.007\n","[ep 173][  400/  782] loss: 0.006\n","[ep 173][  500/  782] loss: 0.009\n","[ep 173][  600/  782] loss: 0.005\n","[ep 173][  700/  782] loss: 0.003\n","[ep 174][  100/  782] loss: 0.004\n","[ep 174][  200/  782] loss: 0.005\n","[ep 174][  300/  782] loss: 0.014\n","[ep 174][  400/  782] loss: 0.005\n","[ep 174][  500/  782] loss: 0.014\n","[ep 174][  600/  782] loss: 0.006\n","[ep 174][  700/  782] loss: 0.006\n","[ep 175][  100/  782] loss: 0.005\n","[ep 175][  200/  782] loss: 0.011\n","[ep 175][  300/  782] loss: 0.004\n","[ep 175][  400/  782] loss: 0.003\n","[ep 175][  500/  782] loss: 0.004\n","[ep 175][  600/  782] loss: 0.007\n","[ep 175][  700/  782] loss: 0.004\n","[ep 176][  100/  782] loss: 0.005\n","[ep 176][  200/  782] loss: 0.009\n","[ep 176][  300/  782] loss: 0.004\n","[ep 176][  400/  782] loss: 0.008\n","[ep 176][  500/  782] loss: 0.004\n","[ep 176][  600/  782] loss: 0.008\n","[ep 176][  700/  782] loss: 0.010\n","[ep 177][  100/  782] loss: 0.003\n","[ep 177][  200/  782] loss: 0.008\n","[ep 177][  300/  782] loss: 0.029\n","[ep 177][  400/  782] loss: 0.004\n","[ep 177][  500/  782] loss: 0.009\n","[ep 177][  600/  782] loss: 0.009\n","[ep 177][  700/  782] loss: 0.007\n","[ep 178][  100/  782] loss: 0.002\n","[ep 178][  200/  782] loss: 0.003\n","[ep 178][  300/  782] loss: 0.003\n","[ep 178][  400/  782] loss: 0.005\n","[ep 178][  500/  782] loss: 0.006\n","[ep 178][  600/  782] loss: 0.004\n","[ep 178][  700/  782] loss: 0.007\n","[ep 179][  100/  782] loss: 0.006\n","[ep 179][  200/  782] loss: 0.005\n","[ep 179][  300/  782] loss: 0.006\n","[ep 179][  400/  782] loss: 0.006\n","[ep 179][  500/  782] loss: 0.013\n","[ep 179][  600/  782] loss: 0.015\n","[ep 179][  700/  782] loss: 0.002\n","[ep 180][  100/  782] loss: 0.003\n","[ep 180][  200/  782] loss: 0.019\n","[ep 180][  300/  782] loss: 0.004\n","[ep 180][  400/  782] loss: 0.003\n","[ep 180][  500/  782] loss: 0.027\n","[ep 180][  600/  782] loss: 0.009\n","[ep 180][  700/  782] loss: 0.007\n","[ep 181][  100/  782] loss: 0.006\n","[ep 181][  200/  782] loss: 0.006\n","[ep 181][  300/  782] loss: 0.003\n","[ep 181][  400/  782] loss: 0.009\n","[ep 181][  500/  782] loss: 0.003\n","[ep 181][  600/  782] loss: 0.006\n","[ep 181][  700/  782] loss: 0.005\n","[ep 182][  100/  782] loss: 0.022\n","[ep 182][  200/  782] loss: 0.007\n","[ep 182][  300/  782] loss: 0.003\n","[ep 182][  400/  782] loss: 0.007\n","[ep 182][  500/  782] loss: 0.007\n","[ep 182][  600/  782] loss: 0.019\n","[ep 182][  700/  782] loss: 0.004\n","[ep 183][  100/  782] loss: 0.004\n","[ep 183][  200/  782] loss: 0.006\n","[ep 183][  300/  782] loss: 0.006\n","[ep 183][  400/  782] loss: 0.005\n","[ep 183][  500/  782] loss: 0.021\n","[ep 183][  600/  782] loss: 0.007\n","[ep 183][  700/  782] loss: 0.003\n","[ep 184][  100/  782] loss: 0.006\n","[ep 184][  200/  782] loss: 0.011\n","[ep 184][  300/  782] loss: 0.002\n","[ep 184][  400/  782] loss: 0.003\n","[ep 184][  500/  782] loss: 0.003\n","[ep 184][  600/  782] loss: 0.012\n","[ep 184][  700/  782] loss: 0.008\n","[ep 185][  100/  782] loss: 0.002\n","[ep 185][  200/  782] loss: 0.006\n","[ep 185][  300/  782] loss: 0.004\n","[ep 185][  400/  782] loss: 0.003\n","[ep 185][  500/  782] loss: 0.003\n","[ep 185][  600/  782] loss: 0.003\n","[ep 185][  700/  782] loss: 0.004\n","[ep 186][  100/  782] loss: 0.001\n","[ep 186][  200/  782] loss: 0.005\n","[ep 186][  300/  782] loss: 0.004\n","[ep 186][  400/  782] loss: 0.010\n","[ep 186][  500/  782] loss: 0.003\n","[ep 186][  600/  782] loss: 0.008\n","[ep 186][  700/  782] loss: 0.005\n","[ep 187][  100/  782] loss: 0.004\n","[ep 187][  200/  782] loss: 0.008\n","[ep 187][  300/  782] loss: 0.003\n","[ep 187][  400/  782] loss: 0.004\n","[ep 187][  500/  782] loss: 0.002\n","[ep 187][  600/  782] loss: 0.002\n","[ep 187][  700/  782] loss: 0.003\n","[ep 188][  100/  782] loss: 0.004\n","[ep 188][  200/  782] loss: 0.006\n","[ep 188][  300/  782] loss: 0.006\n","[ep 188][  400/  782] loss: 0.007\n","[ep 188][  500/  782] loss: 0.006\n","[ep 188][  600/  782] loss: 0.003\n","[ep 188][  700/  782] loss: 0.004\n","[ep 189][  100/  782] loss: 0.007\n","[ep 189][  200/  782] loss: 0.005\n","[ep 189][  300/  782] loss: 0.005\n","[ep 189][  400/  782] loss: 0.004\n","[ep 189][  500/  782] loss: 0.003\n","[ep 189][  600/  782] loss: 0.002\n","[ep 189][  700/  782] loss: 0.005\n","[ep 190][  100/  782] loss: 0.004\n","[ep 190][  200/  782] loss: 0.004\n","[ep 190][  300/  782] loss: 0.003\n","[ep 190][  400/  782] loss: 0.004\n","[ep 190][  500/  782] loss: 0.008\n","[ep 190][  600/  782] loss: 0.003\n","[ep 190][  700/  782] loss: 0.002\n","[ep 191][  100/  782] loss: 0.003\n","[ep 191][  200/  782] loss: 0.006\n","[ep 191][  300/  782] loss: 0.005\n","[ep 191][  400/  782] loss: 0.006\n","[ep 191][  500/  782] loss: 0.003\n","[ep 191][  600/  782] loss: 0.002\n","[ep 191][  700/  782] loss: 0.004\n","[ep 192][  100/  782] loss: 0.011\n","[ep 192][  200/  782] loss: 0.003\n","[ep 192][  300/  782] loss: 0.006\n","[ep 192][  400/  782] loss: 0.004\n","[ep 192][  500/  782] loss: 0.004\n","[ep 192][  600/  782] loss: 0.003\n","[ep 192][  700/  782] loss: 0.003\n","[ep 193][  100/  782] loss: 0.004\n","[ep 193][  200/  782] loss: 0.014\n","[ep 193][  300/  782] loss: 0.003\n","[ep 193][  400/  782] loss: 0.002\n","[ep 193][  500/  782] loss: 0.007\n","[ep 193][  600/  782] loss: 0.004\n","[ep 193][  700/  782] loss: 0.002\n","[ep 194][  100/  782] loss: 0.011\n","[ep 194][  200/  782] loss: 0.003\n","[ep 194][  300/  782] loss: 0.007\n","[ep 194][  400/  782] loss: 0.002\n","[ep 194][  500/  782] loss: 0.006\n","[ep 194][  600/  782] loss: 0.003\n","[ep 194][  700/  782] loss: 0.002\n","[ep 195][  100/  782] loss: 0.003\n","[ep 195][  200/  782] loss: 0.007\n","[ep 195][  300/  782] loss: 0.004\n","[ep 195][  400/  782] loss: 0.004\n","[ep 195][  500/  782] loss: 0.007\n","[ep 195][  600/  782] loss: 0.012\n","[ep 195][  700/  782] loss: 0.003\n","[ep 196][  100/  782] loss: 0.008\n","[ep 196][  200/  782] loss: 0.004\n","[ep 196][  300/  782] loss: 0.009\n","[ep 196][  400/  782] loss: 0.003\n","[ep 196][  500/  782] loss: 0.003\n","[ep 196][  600/  782] loss: 0.011\n","[ep 196][  700/  782] loss: 0.003\n","[ep 197][  100/  782] loss: 0.008\n","[ep 197][  200/  782] loss: 0.006\n","[ep 197][  300/  782] loss: 0.009\n","[ep 197][  400/  782] loss: 0.003\n","[ep 197][  500/  782] loss: 0.010\n","[ep 197][  600/  782] loss: 0.025\n","[ep 197][  700/  782] loss: 0.003\n","[ep 198][  100/  782] loss: 0.005\n","[ep 198][  200/  782] loss: 0.003\n","[ep 198][  300/  782] loss: 0.002\n","[ep 198][  400/  782] loss: 0.003\n","[ep 198][  500/  782] loss: 0.009\n","[ep 198][  600/  782] loss: 0.004\n","[ep 198][  700/  782] loss: 0.003\n","[ep 199][  100/  782] loss: 0.004\n","[ep 199][  200/  782] loss: 0.010\n","[ep 199][  300/  782] loss: 0.005\n","[ep 199][  400/  782] loss: 0.004\n","[ep 199][  500/  782] loss: 0.005\n","[ep 199][  600/  782] loss: 0.006\n","[ep 199][  700/  782] loss: 0.014\n","[ep 200][  100/  782] loss: 0.006\n","[ep 200][  200/  782] loss: 0.009\n","[ep 200][  300/  782] loss: 0.005\n","[ep 200][  400/  782] loss: 0.003\n","[ep 200][  500/  782] loss: 0.003\n","[ep 200][  600/  782] loss: 0.004\n","[ep 200][  700/  782] loss: 0.009\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PRCaFaSEyPP","outputId":"bfa2b7c5-3569-4349-af94-82a8236f1e39","executionInfo":{"status":"ok","timestamp":1649402919211,"user_tz":-480,"elapsed":6748,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 72.71 %\n"]}],"source":["# load trained model\n","# model = torch.load(\"./model.pth\")\n","# model.to(device)\n","\n","# fixed testing process\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"]},{"cell_type":"markdown","source":["Accuracy of the network on the 10000 test images: 60.19 %"],"metadata":{"id":"nJ-vWfp5pcE2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ClqMY-sxSjSt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4956c58e-208f-43c7-d24d-5fc009778ce5","executionInfo":{"status":"ok","timestamp":1649090135633,"user_tz":-480,"elapsed":360,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["du: cannot access 'model.pth': No such file or directory\n"]}],"source":["# model = models.mobilenet_v3_large()\n","# torch.save(model, \"./model.pth\")\n","\n","# see size of saved model\n","! du -h model.pth"]},{"cell_type":"code","source":[""],"metadata":{"id":"TGvw3Nxya-QG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"myCNN.ipynb","provenance":[{"file_id":"16dN4wEownA_cQTPbeaa6aztk6oCCHo5v","timestamp":1649253967507}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3b39941535da4cad84a887f4b601a69d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca1acfdc5b074343b45c74607b702ca9","IPY_MODEL_5012cbbf00bf4181865d46a036ea2649","IPY_MODEL_84ae21a4647848828e9b2632dd8eb68d"],"layout":"IPY_MODEL_92c0f46f16974f65adbb760ed801b3eb"}},"ca1acfdc5b074343b45c74607b702ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f990c5e36ab4959abde7e142733f917","placeholder":"​","style":"IPY_MODEL_6a194e9b647b45ba98202149cdb78e98","value":""}},"5012cbbf00bf4181865d46a036ea2649":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a30597c150ea4fb9882145efc7748fcc","max":169001437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b27adeab377948f6adff391c9db0ce1f","value":169001437}},"84ae21a4647848828e9b2632dd8eb68d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4886150fdccd488989ed93668cffc94f","placeholder":"​","style":"IPY_MODEL_4c8174503ac64df190ab6a45cdeaf0bd","value":" 169001984/? [00:05&lt;00:00, 31889615.84it/s]"}},"92c0f46f16974f65adbb760ed801b3eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f990c5e36ab4959abde7e142733f917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a194e9b647b45ba98202149cdb78e98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a30597c150ea4fb9882145efc7748fcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b27adeab377948f6adff391c9db0ce1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4886150fdccd488989ed93668cffc94f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c8174503ac64df190ab6a45cdeaf0bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a98cb3dfb82a4fb09a9f36192cb06212":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_551c66fb05ba4fb693c2cac593602e28","IPY_MODEL_7cd0dad13b7e431487e8a4b64915ef04","IPY_MODEL_57ac473189d643bbb81dbdbd1d54bba2"],"layout":"IPY_MODEL_4b950d0d349a4fc9963f8108635278dd"}},"551c66fb05ba4fb693c2cac593602e28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cac480bc8142f4a3bb83c3e1738676","placeholder":"​","style":"IPY_MODEL_637f471e34824649a586cb1bc10bea98","value":"100%"}},"7cd0dad13b7e431487e8a4b64915ef04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a78dd8993a048868de62049d5502356","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26ae1508aa424209907dbc58a166e536","value":102530333}},"57ac473189d643bbb81dbdbd1d54bba2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1d6ccf4d374a238c1e3e86f3b391a2","placeholder":"​","style":"IPY_MODEL_21d16ec2a077461d934f8e0f416bb167","value":" 97.8M/97.8M [00:00&lt;00:00, 106MB/s]"}},"4b950d0d349a4fc9963f8108635278dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7cac480bc8142f4a3bb83c3e1738676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"637f471e34824649a586cb1bc10bea98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a78dd8993a048868de62049d5502356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ae1508aa424209907dbc58a166e536":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e1d6ccf4d374a238c1e3e86f3b391a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d16ec2a077461d934f8e0f416bb167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}