{"cells":[{"cell_type":"markdown","metadata":{"id":"py85-Cna3C-m"},"source":["## HW2 DataAugmentation\n","\n","\n",">random adding augmentation"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZvWbvDm8MXF","executionInfo":{"status":"ok","timestamp":1649245487360,"user_tz":-480,"elapsed":21454,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}},"outputId":"4f4507e9-6ff8-492e-9ba4-309e589c5b4c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"f7BIE8HEAA0m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a60dbbf9-ab49-456e-c189-da49fda893fc","executionInfo":{"status":"ok","timestamp":1649245492894,"user_tz":-480,"elapsed":5543,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["89bb70ef5d5c42599b5341d3a49a949f","3c0ccde30da840c1b372ff77f41e0d3c","01f5df273a16445d807bed386c8d8dde","e5f9b0bd5c1a462c85e77d00124f0e26","5db9f3b58936423daae968cbea41eb3c","8a900fca067145569f563ea9a20d01d8","5dde3b255aae4475a25b2e45f58c8ae4","24605b78600442359ea3cb60bf668d78","6b50bce0d9ed407a93ad5420668eb2ac","ccdadd79050c4989a04e7903ee762bfd","ec08d573274240edb4c513b73b6ffacc"]},"id":"DE237Uh3ABKY","outputId":"bcad919f-60af-470a-af9b-876e458e08de","executionInfo":{"status":"ok","timestamp":1649245502914,"user_tz":-480,"elapsed":10034,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89bb70ef5d5c42599b5341d3a49a949f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# see more data augmentation https://pytorch.org/vision/stable/transforms.html\n","mean = (0.5071, 0.4867, 0.4408)\n","std = (0.2675, 0.2565, 0.2761)\n","train_transform = transforms.Compose(\n","    [transforms.RandomCrop(32, padding=4),\n","     transforms.RandomHorizontalFlip(),\n","     transforms.RandomRotation(15),\n","     transforms.ToTensor(),\n","     transforms.Normalize(mean, std)]) # calculte yourself\n","\n","# transforms.RandomHorizontalFlip(p=0.5),\n","\n","test_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize(mean, std)]) # calculte yourself\n","\n","batch_size = 128\n","num_classes = 100    # check\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PDC78MUALYM"},"outputs":[],"source":["class Toy_CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5bf0737906d943c7b08a22598eb1fae9","51dfb3205c034225900ee8b60eb81746","36878c099c4d458099414e2c8bb9e73b","41d4d4b0be084941803ab7b1b8c53928","f8db9b1c07064874b5fe65f35b99daa7","ac25a38dd51f479ba33cbb3de4879c19","4fe20ae931064095bd4376603b34e15c","361b20da8ee547a088ed04159a67ef2f","2f87df83817c4349a6d63d4e1701d414","8c59c0db2b7e44d79203128d393d7c9f","81b11e7863a249bca2aec2944b468fd2"]},"id":"GzOoI9FCAiz3","outputId":"65d63ca8-1f83-409d-9376-f7b6f8fd05c2","executionInfo":{"status":"ok","timestamp":1649245523181,"user_tz":-480,"elapsed":20280,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf0737906d943c7b08a22598eb1fae9"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",")"]},"metadata":{},"execution_count":4}],"source":["# pick one\n","\n","# 1. model defined by yourself\n","# model = Toy_CNN()        \n","   \n","# 2. off-the-shelf model\n","# see https://pytorch.org/vision/stable/models.html\n","# nn.Linear https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n","model = models.resnet50(pretrained=True) \n","model.fc = torch.nn.Linear(2048, num_classes)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yxZ41jR1BT28","executionInfo":{"status":"ok","timestamp":1649245523181,"user_tz":-480,"elapsed":4,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001,\n","                       weight_decay=1e-4)"]},{"cell_type":"code","source":["total_epoch = 200\n","print_per_iteration = 100\n","save_path = '/content/drive/MyDrive/Colab Notebooks/ML_HW2/Data_Augmentation/HFlip_0.5_basic.pth'\n","\n","for epoch in range(total_epoch):  # loop over the dataset multiple times\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        if (i+1) % print_per_iteration == 0:    # print every 2000 mini-batches\n","            print(f'[ep {epoch + 1}][{i + 1:5d}/{len(trainloader):5d}] loss: {loss.item():.3f}')\n","    torch.save(model, save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LTzbiubhyf2","outputId":"919b8f41-def2-4b84-f975-41ec9c195894","executionInfo":{"status":"ok","timestamp":1649251578008,"user_tz":-480,"elapsed":6054831,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[ep 1][  100/  391] loss: 3.708\n","[ep 1][  200/  391] loss: 2.905\n","[ep 1][  300/  391] loss: 2.594\n","[ep 2][  100/  391] loss: 2.213\n","[ep 2][  200/  391] loss: 2.075\n","[ep 2][  300/  391] loss: 2.100\n","[ep 3][  100/  391] loss: 1.655\n","[ep 3][  200/  391] loss: 1.500\n","[ep 3][  300/  391] loss: 1.759\n","[ep 4][  100/  391] loss: 1.642\n","[ep 4][  200/  391] loss: 1.619\n","[ep 4][  300/  391] loss: 1.650\n","[ep 5][  100/  391] loss: 1.330\n","[ep 5][  200/  391] loss: 1.543\n","[ep 5][  300/  391] loss: 1.488\n","[ep 6][  100/  391] loss: 1.510\n","[ep 6][  200/  391] loss: 1.392\n","[ep 6][  300/  391] loss: 1.377\n","[ep 7][  100/  391] loss: 1.078\n","[ep 7][  200/  391] loss: 1.223\n","[ep 7][  300/  391] loss: 1.174\n","[ep 8][  100/  391] loss: 0.945\n","[ep 8][  200/  391] loss: 1.260\n","[ep 8][  300/  391] loss: 1.147\n","[ep 9][  100/  391] loss: 1.142\n","[ep 9][  200/  391] loss: 0.964\n","[ep 9][  300/  391] loss: 0.920\n","[ep 10][  100/  391] loss: 1.149\n","[ep 10][  200/  391] loss: 0.963\n","[ep 10][  300/  391] loss: 0.921\n","[ep 11][  100/  391] loss: 0.838\n","[ep 11][  200/  391] loss: 0.886\n","[ep 11][  300/  391] loss: 1.100\n","[ep 12][  100/  391] loss: 1.084\n","[ep 12][  200/  391] loss: 0.831\n","[ep 12][  300/  391] loss: 0.953\n","[ep 13][  100/  391] loss: 0.897\n","[ep 13][  200/  391] loss: 0.910\n","[ep 13][  300/  391] loss: 0.905\n","[ep 14][  100/  391] loss: 0.474\n","[ep 14][  200/  391] loss: 0.605\n","[ep 14][  300/  391] loss: 0.750\n","[ep 15][  100/  391] loss: 0.714\n","[ep 15][  200/  391] loss: 0.779\n","[ep 15][  300/  391] loss: 0.755\n","[ep 16][  100/  391] loss: 0.603\n","[ep 16][  200/  391] loss: 0.530\n","[ep 16][  300/  391] loss: 0.721\n","[ep 17][  100/  391] loss: 0.523\n","[ep 17][  200/  391] loss: 0.761\n","[ep 17][  300/  391] loss: 0.553\n","[ep 18][  100/  391] loss: 0.523\n","[ep 18][  200/  391] loss: 0.405\n","[ep 18][  300/  391] loss: 0.463\n","[ep 19][  100/  391] loss: 0.623\n","[ep 19][  200/  391] loss: 0.655\n","[ep 19][  300/  391] loss: 0.560\n","[ep 20][  100/  391] loss: 0.457\n","[ep 20][  200/  391] loss: 0.397\n","[ep 20][  300/  391] loss: 0.536\n","[ep 21][  100/  391] loss: 0.545\n","[ep 21][  200/  391] loss: 0.474\n","[ep 21][  300/  391] loss: 0.404\n","[ep 22][  100/  391] loss: 0.422\n","[ep 22][  200/  391] loss: 0.553\n","[ep 22][  300/  391] loss: 0.463\n","[ep 23][  100/  391] loss: 0.422\n","[ep 23][  200/  391] loss: 0.449\n","[ep 23][  300/  391] loss: 0.511\n","[ep 24][  100/  391] loss: 0.483\n","[ep 24][  200/  391] loss: 0.342\n","[ep 24][  300/  391] loss: 0.371\n","[ep 25][  100/  391] loss: 0.499\n","[ep 25][  200/  391] loss: 0.527\n","[ep 25][  300/  391] loss: 0.376\n","[ep 26][  100/  391] loss: 0.359\n","[ep 26][  200/  391] loss: 0.297\n","[ep 26][  300/  391] loss: 0.345\n","[ep 27][  100/  391] loss: 0.436\n","[ep 27][  200/  391] loss: 0.278\n","[ep 27][  300/  391] loss: 0.295\n","[ep 28][  100/  391] loss: 0.316\n","[ep 28][  200/  391] loss: 0.274\n","[ep 28][  300/  391] loss: 0.447\n","[ep 29][  100/  391] loss: 0.274\n","[ep 29][  200/  391] loss: 0.247\n","[ep 29][  300/  391] loss: 0.273\n","[ep 30][  100/  391] loss: 0.220\n","[ep 30][  200/  391] loss: 0.395\n","[ep 30][  300/  391] loss: 0.359\n","[ep 31][  100/  391] loss: 0.211\n","[ep 31][  200/  391] loss: 0.228\n","[ep 31][  300/  391] loss: 0.447\n","[ep 32][  100/  391] loss: 0.252\n","[ep 32][  200/  391] loss: 0.408\n","[ep 32][  300/  391] loss: 0.265\n","[ep 33][  100/  391] loss: 0.197\n","[ep 33][  200/  391] loss: 0.295\n","[ep 33][  300/  391] loss: 0.351\n","[ep 34][  100/  391] loss: 0.236\n","[ep 34][  200/  391] loss: 0.339\n","[ep 34][  300/  391] loss: 0.385\n","[ep 35][  100/  391] loss: 0.257\n","[ep 35][  200/  391] loss: 0.218\n","[ep 35][  300/  391] loss: 0.208\n","[ep 36][  100/  391] loss: 0.182\n","[ep 36][  200/  391] loss: 0.155\n","[ep 36][  300/  391] loss: 0.300\n","[ep 37][  100/  391] loss: 0.228\n","[ep 37][  200/  391] loss: 0.306\n","[ep 37][  300/  391] loss: 0.246\n","[ep 38][  100/  391] loss: 0.295\n","[ep 38][  200/  391] loss: 0.244\n","[ep 38][  300/  391] loss: 0.426\n","[ep 39][  100/  391] loss: 0.253\n","[ep 39][  200/  391] loss: 0.178\n","[ep 39][  300/  391] loss: 0.363\n","[ep 40][  100/  391] loss: 0.203\n","[ep 40][  200/  391] loss: 0.160\n","[ep 40][  300/  391] loss: 0.291\n","[ep 41][  100/  391] loss: 0.182\n","[ep 41][  200/  391] loss: 0.180\n","[ep 41][  300/  391] loss: 0.226\n","[ep 42][  100/  391] loss: 0.232\n","[ep 42][  200/  391] loss: 0.206\n","[ep 42][  300/  391] loss: 0.257\n","[ep 43][  100/  391] loss: 0.285\n","[ep 43][  200/  391] loss: 0.308\n","[ep 43][  300/  391] loss: 0.204\n","[ep 44][  100/  391] loss: 0.208\n","[ep 44][  200/  391] loss: 0.235\n","[ep 44][  300/  391] loss: 0.312\n","[ep 45][  100/  391] loss: 0.272\n","[ep 45][  200/  391] loss: 0.228\n","[ep 45][  300/  391] loss: 0.273\n","[ep 46][  100/  391] loss: 0.205\n","[ep 46][  200/  391] loss: 0.193\n","[ep 46][  300/  391] loss: 0.267\n","[ep 47][  100/  391] loss: 0.112\n","[ep 47][  200/  391] loss: 0.275\n","[ep 47][  300/  391] loss: 0.181\n","[ep 48][  100/  391] loss: 0.211\n","[ep 48][  200/  391] loss: 0.197\n","[ep 48][  300/  391] loss: 0.147\n","[ep 49][  100/  391] loss: 0.171\n","[ep 49][  200/  391] loss: 0.213\n","[ep 49][  300/  391] loss: 0.127\n","[ep 50][  100/  391] loss: 0.140\n","[ep 50][  200/  391] loss: 0.236\n","[ep 50][  300/  391] loss: 0.190\n","[ep 51][  100/  391] loss: 0.110\n","[ep 51][  200/  391] loss: 0.152\n","[ep 51][  300/  391] loss: 0.156\n","[ep 52][  100/  391] loss: 0.153\n","[ep 52][  200/  391] loss: 0.304\n","[ep 52][  300/  391] loss: 0.132\n","[ep 53][  100/  391] loss: 0.275\n","[ep 53][  200/  391] loss: 0.160\n","[ep 53][  300/  391] loss: 0.168\n","[ep 54][  100/  391] loss: 0.124\n","[ep 54][  200/  391] loss: 0.170\n","[ep 54][  300/  391] loss: 0.171\n","[ep 55][  100/  391] loss: 0.113\n","[ep 55][  200/  391] loss: 0.132\n","[ep 55][  300/  391] loss: 0.278\n","[ep 56][  100/  391] loss: 0.200\n","[ep 56][  200/  391] loss: 0.127\n","[ep 56][  300/  391] loss: 0.200\n","[ep 57][  100/  391] loss: 0.173\n","[ep 57][  200/  391] loss: 0.155\n","[ep 57][  300/  391] loss: 0.148\n","[ep 58][  100/  391] loss: 0.226\n","[ep 58][  200/  391] loss: 0.178\n","[ep 58][  300/  391] loss: 0.078\n","[ep 59][  100/  391] loss: 0.084\n","[ep 59][  200/  391] loss: 0.149\n","[ep 59][  300/  391] loss: 0.130\n","[ep 60][  100/  391] loss: 0.119\n","[ep 60][  200/  391] loss: 0.145\n","[ep 60][  300/  391] loss: 0.135\n","[ep 61][  100/  391] loss: 0.180\n","[ep 61][  200/  391] loss: 0.105\n","[ep 61][  300/  391] loss: 0.104\n","[ep 62][  100/  391] loss: 0.174\n","[ep 62][  200/  391] loss: 0.141\n","[ep 62][  300/  391] loss: 0.097\n","[ep 63][  100/  391] loss: 0.087\n","[ep 63][  200/  391] loss: 0.112\n","[ep 63][  300/  391] loss: 0.205\n","[ep 64][  100/  391] loss: 0.064\n","[ep 64][  200/  391] loss: 0.094\n","[ep 64][  300/  391] loss: 0.081\n","[ep 65][  100/  391] loss: 0.105\n","[ep 65][  200/  391] loss: 0.188\n","[ep 65][  300/  391] loss: 0.179\n","[ep 66][  100/  391] loss: 0.101\n","[ep 66][  200/  391] loss: 0.139\n","[ep 66][  300/  391] loss: 0.084\n","[ep 67][  100/  391] loss: 0.066\n","[ep 67][  200/  391] loss: 0.176\n","[ep 67][  300/  391] loss: 0.153\n","[ep 68][  100/  391] loss: 0.112\n","[ep 68][  200/  391] loss: 0.127\n","[ep 68][  300/  391] loss: 0.174\n","[ep 69][  100/  391] loss: 0.065\n","[ep 69][  200/  391] loss: 0.148\n","[ep 69][  300/  391] loss: 0.144\n","[ep 70][  100/  391] loss: 0.088\n","[ep 70][  200/  391] loss: 0.129\n","[ep 70][  300/  391] loss: 0.102\n","[ep 71][  100/  391] loss: 0.170\n","[ep 71][  200/  391] loss: 0.118\n","[ep 71][  300/  391] loss: 0.049\n","[ep 72][  100/  391] loss: 0.105\n","[ep 72][  200/  391] loss: 0.136\n","[ep 72][  300/  391] loss: 0.098\n","[ep 73][  100/  391] loss: 0.146\n","[ep 73][  200/  391] loss: 0.184\n","[ep 73][  300/  391] loss: 0.139\n","[ep 74][  100/  391] loss: 0.147\n","[ep 74][  200/  391] loss: 0.062\n","[ep 74][  300/  391] loss: 0.097\n","[ep 75][  100/  391] loss: 0.109\n","[ep 75][  200/  391] loss: 0.171\n","[ep 75][  300/  391] loss: 0.119\n","[ep 76][  100/  391] loss: 0.109\n","[ep 76][  200/  391] loss: 0.128\n","[ep 76][  300/  391] loss: 0.145\n","[ep 77][  100/  391] loss: 0.147\n","[ep 77][  200/  391] loss: 0.048\n","[ep 77][  300/  391] loss: 0.154\n","[ep 78][  100/  391] loss: 0.103\n","[ep 78][  200/  391] loss: 0.090\n","[ep 78][  300/  391] loss: 0.219\n","[ep 79][  100/  391] loss: 0.120\n","[ep 79][  200/  391] loss: 0.200\n","[ep 79][  300/  391] loss: 0.113\n","[ep 80][  100/  391] loss: 0.104\n","[ep 80][  200/  391] loss: 0.124\n","[ep 80][  300/  391] loss: 0.124\n","[ep 81][  100/  391] loss: 0.149\n","[ep 81][  200/  391] loss: 0.175\n","[ep 81][  300/  391] loss: 0.168\n","[ep 82][  100/  391] loss: 0.110\n","[ep 82][  200/  391] loss: 0.185\n","[ep 82][  300/  391] loss: 0.118\n","[ep 83][  100/  391] loss: 0.099\n","[ep 83][  200/  391] loss: 0.090\n","[ep 83][  300/  391] loss: 0.157\n","[ep 84][  100/  391] loss: 0.132\n","[ep 84][  200/  391] loss: 0.057\n","[ep 84][  300/  391] loss: 0.122\n","[ep 85][  100/  391] loss: 0.057\n","[ep 85][  200/  391] loss: 0.070\n","[ep 85][  300/  391] loss: 0.133\n","[ep 86][  100/  391] loss: 0.079\n","[ep 86][  200/  391] loss: 0.178\n","[ep 86][  300/  391] loss: 0.103\n","[ep 87][  100/  391] loss: 0.160\n","[ep 87][  200/  391] loss: 0.118\n","[ep 87][  300/  391] loss: 0.131\n","[ep 88][  100/  391] loss: 0.073\n","[ep 88][  200/  391] loss: 0.095\n","[ep 88][  300/  391] loss: 0.171\n","[ep 89][  100/  391] loss: 0.079\n","[ep 89][  200/  391] loss: 0.100\n","[ep 89][  300/  391] loss: 0.077\n","[ep 90][  100/  391] loss: 0.059\n","[ep 90][  200/  391] loss: 0.119\n","[ep 90][  300/  391] loss: 0.154\n","[ep 91][  100/  391] loss: 0.097\n","[ep 91][  200/  391] loss: 0.110\n","[ep 91][  300/  391] loss: 0.118\n","[ep 92][  100/  391] loss: 0.038\n","[ep 92][  200/  391] loss: 0.087\n","[ep 92][  300/  391] loss: 0.103\n","[ep 93][  100/  391] loss: 0.052\n","[ep 93][  200/  391] loss: 0.108\n","[ep 93][  300/  391] loss: 0.081\n","[ep 94][  100/  391] loss: 0.163\n","[ep 94][  200/  391] loss: 0.076\n","[ep 94][  300/  391] loss: 0.084\n","[ep 95][  100/  391] loss: 0.066\n","[ep 95][  200/  391] loss: 0.028\n","[ep 95][  300/  391] loss: 0.094\n","[ep 96][  100/  391] loss: 0.183\n","[ep 96][  200/  391] loss: 0.093\n","[ep 96][  300/  391] loss: 0.035\n","[ep 97][  100/  391] loss: 0.041\n","[ep 97][  200/  391] loss: 0.306\n","[ep 97][  300/  391] loss: 0.113\n","[ep 98][  100/  391] loss: 0.032\n","[ep 98][  200/  391] loss: 0.064\n","[ep 98][  300/  391] loss: 0.082\n","[ep 99][  100/  391] loss: 0.085\n","[ep 99][  200/  391] loss: 0.095\n","[ep 99][  300/  391] loss: 0.125\n","[ep 100][  100/  391] loss: 0.078\n","[ep 100][  200/  391] loss: 0.075\n","[ep 100][  300/  391] loss: 0.074\n","[ep 101][  100/  391] loss: 0.105\n","[ep 101][  200/  391] loss: 0.134\n","[ep 101][  300/  391] loss: 0.107\n","[ep 102][  100/  391] loss: 0.048\n","[ep 102][  200/  391] loss: 0.076\n","[ep 102][  300/  391] loss: 0.177\n","[ep 103][  100/  391] loss: 0.071\n","[ep 103][  200/  391] loss: 0.145\n","[ep 103][  300/  391] loss: 0.156\n","[ep 104][  100/  391] loss: 0.135\n","[ep 104][  200/  391] loss: 0.104\n","[ep 104][  300/  391] loss: 0.127\n","[ep 105][  100/  391] loss: 0.039\n","[ep 105][  200/  391] loss: 0.050\n","[ep 105][  300/  391] loss: 0.059\n","[ep 106][  100/  391] loss: 0.068\n","[ep 106][  200/  391] loss: 0.130\n","[ep 106][  300/  391] loss: 0.060\n","[ep 107][  100/  391] loss: 0.029\n","[ep 107][  200/  391] loss: 0.106\n","[ep 107][  300/  391] loss: 0.112\n","[ep 108][  100/  391] loss: 0.096\n","[ep 108][  200/  391] loss: 0.035\n","[ep 108][  300/  391] loss: 0.178\n","[ep 109][  100/  391] loss: 0.154\n","[ep 109][  200/  391] loss: 0.115\n","[ep 109][  300/  391] loss: 0.147\n","[ep 110][  100/  391] loss: 0.146\n","[ep 110][  200/  391] loss: 0.155\n","[ep 110][  300/  391] loss: 0.064\n","[ep 111][  100/  391] loss: 0.074\n","[ep 111][  200/  391] loss: 0.089\n","[ep 111][  300/  391] loss: 0.020\n","[ep 112][  100/  391] loss: 0.111\n","[ep 112][  200/  391] loss: 0.061\n","[ep 112][  300/  391] loss: 0.076\n","[ep 113][  100/  391] loss: 0.073\n","[ep 113][  200/  391] loss: 0.115\n","[ep 113][  300/  391] loss: 0.099\n","[ep 114][  100/  391] loss: 0.070\n","[ep 114][  200/  391] loss: 0.189\n","[ep 114][  300/  391] loss: 0.125\n","[ep 115][  100/  391] loss: 0.107\n","[ep 115][  200/  391] loss: 0.054\n","[ep 115][  300/  391] loss: 0.020\n","[ep 116][  100/  391] loss: 0.025\n","[ep 116][  200/  391] loss: 0.065\n","[ep 116][  300/  391] loss: 0.091\n","[ep 117][  100/  391] loss: 0.050\n","[ep 117][  200/  391] loss: 0.129\n","[ep 117][  300/  391] loss: 0.100\n","[ep 118][  100/  391] loss: 0.059\n","[ep 118][  200/  391] loss: 0.084\n","[ep 118][  300/  391] loss: 0.078\n","[ep 119][  100/  391] loss: 0.131\n","[ep 119][  200/  391] loss: 0.026\n","[ep 119][  300/  391] loss: 0.152\n","[ep 120][  100/  391] loss: 0.093\n","[ep 120][  200/  391] loss: 0.111\n","[ep 120][  300/  391] loss: 0.139\n","[ep 121][  100/  391] loss: 0.059\n","[ep 121][  200/  391] loss: 0.043\n","[ep 121][  300/  391] loss: 0.152\n","[ep 122][  100/  391] loss: 0.147\n","[ep 122][  200/  391] loss: 0.178\n","[ep 122][  300/  391] loss: 0.094\n","[ep 123][  100/  391] loss: 0.106\n","[ep 123][  200/  391] loss: 0.036\n","[ep 123][  300/  391] loss: 0.126\n","[ep 124][  100/  391] loss: 0.147\n","[ep 124][  200/  391] loss: 0.039\n","[ep 124][  300/  391] loss: 0.065\n","[ep 125][  100/  391] loss: 0.031\n","[ep 125][  200/  391] loss: 0.069\n","[ep 125][  300/  391] loss: 0.099\n","[ep 126][  100/  391] loss: 0.049\n","[ep 126][  200/  391] loss: 0.052\n","[ep 126][  300/  391] loss: 0.107\n","[ep 127][  100/  391] loss: 0.102\n","[ep 127][  200/  391] loss: 0.062\n","[ep 127][  300/  391] loss: 0.055\n","[ep 128][  100/  391] loss: 0.048\n","[ep 128][  200/  391] loss: 0.085\n","[ep 128][  300/  391] loss: 0.156\n","[ep 129][  100/  391] loss: 0.056\n","[ep 129][  200/  391] loss: 0.187\n","[ep 129][  300/  391] loss: 0.098\n","[ep 130][  100/  391] loss: 0.049\n","[ep 130][  200/  391] loss: 0.095\n","[ep 130][  300/  391] loss: 0.095\n","[ep 131][  100/  391] loss: 0.033\n","[ep 131][  200/  391] loss: 0.045\n","[ep 131][  300/  391] loss: 0.062\n","[ep 132][  100/  391] loss: 0.129\n","[ep 132][  200/  391] loss: 0.100\n","[ep 132][  300/  391] loss: 0.098\n","[ep 133][  100/  391] loss: 0.068\n","[ep 133][  200/  391] loss: 0.106\n","[ep 133][  300/  391] loss: 0.058\n","[ep 134][  100/  391] loss: 0.064\n","[ep 134][  200/  391] loss: 0.097\n","[ep 134][  300/  391] loss: 0.052\n","[ep 135][  100/  391] loss: 0.097\n","[ep 135][  200/  391] loss: 0.123\n","[ep 135][  300/  391] loss: 0.088\n","[ep 136][  100/  391] loss: 0.077\n","[ep 136][  200/  391] loss: 0.068\n","[ep 136][  300/  391] loss: 0.016\n","[ep 137][  100/  391] loss: 0.053\n","[ep 137][  200/  391] loss: 0.100\n","[ep 137][  300/  391] loss: 0.089\n","[ep 138][  100/  391] loss: 0.056\n","[ep 138][  200/  391] loss: 0.046\n","[ep 138][  300/  391] loss: 0.130\n","[ep 139][  100/  391] loss: 0.071\n","[ep 139][  200/  391] loss: 0.058\n","[ep 139][  300/  391] loss: 0.072\n","[ep 140][  100/  391] loss: 0.059\n","[ep 140][  200/  391] loss: 0.080\n","[ep 140][  300/  391] loss: 0.083\n","[ep 141][  100/  391] loss: 0.054\n","[ep 141][  200/  391] loss: 0.074\n","[ep 141][  300/  391] loss: 0.053\n","[ep 142][  100/  391] loss: 0.214\n","[ep 142][  200/  391] loss: 0.077\n","[ep 142][  300/  391] loss: 0.129\n","[ep 143][  100/  391] loss: 0.059\n","[ep 143][  200/  391] loss: 0.113\n","[ep 143][  300/  391] loss: 0.050\n","[ep 144][  100/  391] loss: 0.108\n","[ep 144][  200/  391] loss: 0.087\n","[ep 144][  300/  391] loss: 0.212\n","[ep 145][  100/  391] loss: 0.093\n","[ep 145][  200/  391] loss: 0.088\n","[ep 145][  300/  391] loss: 0.082\n","[ep 146][  100/  391] loss: 0.113\n","[ep 146][  200/  391] loss: 0.039\n","[ep 146][  300/  391] loss: 0.104\n","[ep 147][  100/  391] loss: 0.122\n","[ep 147][  200/  391] loss: 0.097\n","[ep 147][  300/  391] loss: 0.080\n","[ep 148][  100/  391] loss: 0.044\n","[ep 148][  200/  391] loss: 0.042\n","[ep 148][  300/  391] loss: 0.061\n","[ep 149][  100/  391] loss: 0.037\n","[ep 149][  200/  391] loss: 0.110\n","[ep 149][  300/  391] loss: 0.060\n","[ep 150][  100/  391] loss: 0.075\n","[ep 150][  200/  391] loss: 0.147\n","[ep 150][  300/  391] loss: 0.047\n","[ep 151][  100/  391] loss: 0.083\n","[ep 151][  200/  391] loss: 0.060\n","[ep 151][  300/  391] loss: 0.088\n","[ep 152][  100/  391] loss: 0.036\n","[ep 152][  200/  391] loss: 0.123\n","[ep 152][  300/  391] loss: 0.071\n","[ep 153][  100/  391] loss: 0.129\n","[ep 153][  200/  391] loss: 0.067\n","[ep 153][  300/  391] loss: 0.023\n","[ep 154][  100/  391] loss: 0.137\n","[ep 154][  200/  391] loss: 0.045\n","[ep 154][  300/  391] loss: 0.108\n","[ep 155][  100/  391] loss: 0.094\n","[ep 155][  200/  391] loss: 0.136\n","[ep 155][  300/  391] loss: 0.105\n","[ep 156][  100/  391] loss: 0.011\n","[ep 156][  200/  391] loss: 0.035\n","[ep 156][  300/  391] loss: 0.073\n","[ep 157][  100/  391] loss: 0.053\n","[ep 157][  200/  391] loss: 0.117\n","[ep 157][  300/  391] loss: 0.050\n","[ep 158][  100/  391] loss: 0.029\n","[ep 158][  200/  391] loss: 0.051\n","[ep 158][  300/  391] loss: 0.095\n","[ep 159][  100/  391] loss: 0.048\n","[ep 159][  200/  391] loss: 0.023\n","[ep 159][  300/  391] loss: 0.070\n","[ep 160][  100/  391] loss: 0.041\n","[ep 160][  200/  391] loss: 0.089\n","[ep 160][  300/  391] loss: 0.038\n","[ep 161][  100/  391] loss: 0.025\n","[ep 161][  200/  391] loss: 0.031\n","[ep 161][  300/  391] loss: 0.053\n","[ep 162][  100/  391] loss: 0.063\n","[ep 162][  200/  391] loss: 0.091\n","[ep 162][  300/  391] loss: 0.026\n","[ep 163][  100/  391] loss: 0.030\n","[ep 163][  200/  391] loss: 0.113\n","[ep 163][  300/  391] loss: 0.071\n","[ep 164][  100/  391] loss: 0.072\n","[ep 164][  200/  391] loss: 0.051\n","[ep 164][  300/  391] loss: 0.131\n","[ep 165][  100/  391] loss: 0.078\n","[ep 165][  200/  391] loss: 0.051\n","[ep 165][  300/  391] loss: 0.091\n","[ep 166][  100/  391] loss: 0.095\n","[ep 166][  200/  391] loss: 0.095\n","[ep 166][  300/  391] loss: 0.154\n","[ep 167][  100/  391] loss: 0.130\n","[ep 167][  200/  391] loss: 0.082\n","[ep 167][  300/  391] loss: 0.084\n","[ep 168][  100/  391] loss: 0.027\n","[ep 168][  200/  391] loss: 0.076\n","[ep 168][  300/  391] loss: 0.033\n","[ep 169][  100/  391] loss: 0.066\n","[ep 169][  200/  391] loss: 0.041\n","[ep 169][  300/  391] loss: 0.048\n","[ep 170][  100/  391] loss: 0.033\n","[ep 170][  200/  391] loss: 0.065\n","[ep 170][  300/  391] loss: 0.067\n","[ep 171][  100/  391] loss: 0.055\n","[ep 171][  200/  391] loss: 0.031\n","[ep 171][  300/  391] loss: 0.024\n","[ep 172][  100/  391] loss: 0.099\n","[ep 172][  200/  391] loss: 0.046\n","[ep 172][  300/  391] loss: 0.066\n","[ep 173][  100/  391] loss: 0.078\n","[ep 173][  200/  391] loss: 0.024\n","[ep 173][  300/  391] loss: 0.036\n","[ep 174][  100/  391] loss: 0.043\n","[ep 174][  200/  391] loss: 0.071\n","[ep 174][  300/  391] loss: 0.154\n","[ep 175][  100/  391] loss: 0.074\n","[ep 175][  200/  391] loss: 0.051\n","[ep 175][  300/  391] loss: 0.034\n","[ep 176][  100/  391] loss: 0.066\n","[ep 176][  200/  391] loss: 0.096\n","[ep 176][  300/  391] loss: 0.063\n","[ep 177][  100/  391] loss: 0.036\n","[ep 177][  200/  391] loss: 0.054\n","[ep 177][  300/  391] loss: 0.068\n","[ep 178][  100/  391] loss: 0.075\n","[ep 178][  200/  391] loss: 0.070\n","[ep 178][  300/  391] loss: 0.030\n","[ep 179][  100/  391] loss: 0.098\n","[ep 179][  200/  391] loss: 0.154\n","[ep 179][  300/  391] loss: 0.070\n","[ep 180][  100/  391] loss: 0.044\n","[ep 180][  200/  391] loss: 0.072\n","[ep 180][  300/  391] loss: 0.019\n","[ep 181][  100/  391] loss: 0.012\n","[ep 181][  200/  391] loss: 0.096\n","[ep 181][  300/  391] loss: 0.089\n","[ep 182][  100/  391] loss: 0.088\n","[ep 182][  200/  391] loss: 0.042\n","[ep 182][  300/  391] loss: 0.037\n","[ep 183][  100/  391] loss: 0.043\n","[ep 183][  200/  391] loss: 0.066\n","[ep 183][  300/  391] loss: 0.055\n","[ep 184][  100/  391] loss: 0.049\n","[ep 184][  200/  391] loss: 0.083\n","[ep 184][  300/  391] loss: 0.094\n","[ep 185][  100/  391] loss: 0.077\n","[ep 185][  200/  391] loss: 0.101\n","[ep 185][  300/  391] loss: 0.041\n","[ep 186][  100/  391] loss: 0.064\n","[ep 186][  200/  391] loss: 0.049\n","[ep 186][  300/  391] loss: 0.070\n","[ep 187][  100/  391] loss: 0.031\n","[ep 187][  200/  391] loss: 0.047\n","[ep 187][  300/  391] loss: 0.074\n","[ep 188][  100/  391] loss: 0.027\n","[ep 188][  200/  391] loss: 0.058\n","[ep 188][  300/  391] loss: 0.131\n","[ep 189][  100/  391] loss: 0.059\n","[ep 189][  200/  391] loss: 0.047\n","[ep 189][  300/  391] loss: 0.060\n","[ep 190][  100/  391] loss: 0.044\n","[ep 190][  200/  391] loss: 0.022\n","[ep 190][  300/  391] loss: 0.058\n","[ep 191][  100/  391] loss: 0.023\n","[ep 191][  200/  391] loss: 0.022\n","[ep 191][  300/  391] loss: 0.090\n","[ep 192][  100/  391] loss: 0.078\n","[ep 192][  200/  391] loss: 0.033\n","[ep 192][  300/  391] loss: 0.026\n","[ep 193][  100/  391] loss: 0.097\n","[ep 193][  200/  391] loss: 0.037\n","[ep 193][  300/  391] loss: 0.119\n","[ep 194][  100/  391] loss: 0.065\n","[ep 194][  200/  391] loss: 0.036\n","[ep 194][  300/  391] loss: 0.075\n","[ep 195][  100/  391] loss: 0.058\n","[ep 195][  200/  391] loss: 0.018\n","[ep 195][  300/  391] loss: 0.033\n","[ep 196][  100/  391] loss: 0.055\n","[ep 196][  200/  391] loss: 0.098\n","[ep 196][  300/  391] loss: 0.063\n","[ep 197][  100/  391] loss: 0.063\n","[ep 197][  200/  391] loss: 0.070\n","[ep 197][  300/  391] loss: 0.071\n","[ep 198][  100/  391] loss: 0.067\n","[ep 198][  200/  391] loss: 0.069\n","[ep 198][  300/  391] loss: 0.067\n","[ep 199][  100/  391] loss: 0.100\n","[ep 199][  200/  391] loss: 0.036\n","[ep 199][  300/  391] loss: 0.030\n","[ep 200][  100/  391] loss: 0.076\n","[ep 200][  200/  391] loss: 0.072\n","[ep 200][  300/  391] loss: 0.071\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PRCaFaSEyPP","outputId":"97fcdcf0-3e91-4d92-9ce0-593f847a0e36","executionInfo":{"status":"ok","timestamp":1649251580729,"user_tz":-480,"elapsed":2739,"user":{"displayName":"邱柏鎧","userId":"04478619653307828795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 53.32 %\n"]}],"source":["# load trained model\n","# model = torch.load(\"./model.pth\")\n","# model.to(device)\n","\n","# fixed testing process\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"]},{"cell_type":"markdown","source":["Accuracy of the network on the 10000 test images: 60.19 %"],"metadata":{"id":"nJ-vWfp5pcE2"}},{"cell_type":"code","source":[""],"metadata":{"id":"TGvw3Nxya-QG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DataAugmentation.ipynb","provenance":[{"file_id":"16dN4wEownA_cQTPbeaa6aztk6oCCHo5v","timestamp":1649062287575}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"89bb70ef5d5c42599b5341d3a49a949f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c0ccde30da840c1b372ff77f41e0d3c","IPY_MODEL_01f5df273a16445d807bed386c8d8dde","IPY_MODEL_e5f9b0bd5c1a462c85e77d00124f0e26"],"layout":"IPY_MODEL_5db9f3b58936423daae968cbea41eb3c"}},"3c0ccde30da840c1b372ff77f41e0d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a900fca067145569f563ea9a20d01d8","placeholder":"​","style":"IPY_MODEL_5dde3b255aae4475a25b2e45f58c8ae4","value":""}},"01f5df273a16445d807bed386c8d8dde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24605b78600442359ea3cb60bf668d78","max":169001437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b50bce0d9ed407a93ad5420668eb2ac","value":169001437}},"e5f9b0bd5c1a462c85e77d00124f0e26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccdadd79050c4989a04e7903ee762bfd","placeholder":"​","style":"IPY_MODEL_ec08d573274240edb4c513b73b6ffacc","value":" 169001984/? [00:05&lt;00:00, 30273726.23it/s]"}},"5db9f3b58936423daae968cbea41eb3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a900fca067145569f563ea9a20d01d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dde3b255aae4475a25b2e45f58c8ae4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24605b78600442359ea3cb60bf668d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b50bce0d9ed407a93ad5420668eb2ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccdadd79050c4989a04e7903ee762bfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec08d573274240edb4c513b73b6ffacc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bf0737906d943c7b08a22598eb1fae9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51dfb3205c034225900ee8b60eb81746","IPY_MODEL_36878c099c4d458099414e2c8bb9e73b","IPY_MODEL_41d4d4b0be084941803ab7b1b8c53928"],"layout":"IPY_MODEL_f8db9b1c07064874b5fe65f35b99daa7"}},"51dfb3205c034225900ee8b60eb81746":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac25a38dd51f479ba33cbb3de4879c19","placeholder":"​","style":"IPY_MODEL_4fe20ae931064095bd4376603b34e15c","value":"100%"}},"36878c099c4d458099414e2c8bb9e73b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_361b20da8ee547a088ed04159a67ef2f","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f87df83817c4349a6d63d4e1701d414","value":102530333}},"41d4d4b0be084941803ab7b1b8c53928":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c59c0db2b7e44d79203128d393d7c9f","placeholder":"​","style":"IPY_MODEL_81b11e7863a249bca2aec2944b468fd2","value":" 97.8M/97.8M [00:10&lt;00:00, 10.5MB/s]"}},"f8db9b1c07064874b5fe65f35b99daa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac25a38dd51f479ba33cbb3de4879c19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe20ae931064095bd4376603b34e15c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"361b20da8ee547a088ed04159a67ef2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f87df83817c4349a6d63d4e1701d414":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c59c0db2b7e44d79203128d393d7c9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81b11e7863a249bca2aec2944b468fd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}